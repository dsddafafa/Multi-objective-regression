{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b5e0f7-72e6-4979-a368-7562e9e63789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgbxgb\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sys\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "################################################k折交叉验证的结果\n",
    "from sklearn.model_selection import train_test_split\n",
    "###########################################################################################PSO优化算法\n",
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# 导入粒子群算法\n",
    "from sko.PSO import PSO#########不可加约束的算法\n",
    "import random\n",
    "random.seed(7) \n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error,explained_variance_score,mean_absolute_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b050d7f9-6579-4a18-b3a7-9ac2a46a4370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>Pr</th>\n",
       "      <th>Th</th>\n",
       "      <th>Cp</th>\n",
       "      <th>Gv</th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>MSPT</th>\n",
       "      <th>MDPT</th>\n",
       "      <th>MUCS</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.05</td>\n",
       "      <td>21.875000</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>7.927460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.234286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.60</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0.975344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.912626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.40</td>\n",
       "      <td>23.636364</td>\n",
       "      <td>10.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.35</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.26</td>\n",
       "      <td>25.423729</td>\n",
       "      <td>9.60</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.85</td>\n",
       "      <td>5.55</td>\n",
       "      <td>6.199941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.32</td>\n",
       "      <td>27.678571</td>\n",
       "      <td>11.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.6</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.008770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2.20</td>\n",
       "      <td>6.944444</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.4</td>\n",
       "      <td>13.65</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.335021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.689158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2.48</td>\n",
       "      <td>8.139535</td>\n",
       "      <td>11.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.4</td>\n",
       "      <td>13.50</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.106990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.489481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2.50</td>\n",
       "      <td>23.684211</td>\n",
       "      <td>11.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.25</td>\n",
       "      <td>14.75</td>\n",
       "      <td>2.481688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.615505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2.95</td>\n",
       "      <td>27.368421</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.2</td>\n",
       "      <td>16.95</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1.489263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.762378</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2.10</td>\n",
       "      <td>12.105263</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.2</td>\n",
       "      <td>17.25</td>\n",
       "      <td>13.85</td>\n",
       "      <td>1.207845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.552867</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       To         Pr     Th    Cp   Gv      H      W      MSPT  MDPT  \\\n",
       "0    1.05  21.875000   7.90  0.10  6.5   9.10   5.40  7.927460   0.0   \n",
       "1    2.60   9.230769   9.30  0.26  6.0  12.00   7.05  0.975344   0.0   \n",
       "2    2.40  23.636364  10.20  1.00  6.0  26.35  18.10  0.000000   0.0   \n",
       "3    2.26  25.423729   9.60  0.30  4.5   9.85   5.55  6.199941   0.0   \n",
       "4    3.32  27.678571  11.10  0.50  6.6   9.90   5.50  5.008770   0.0   \n",
       "..    ...        ...    ...   ...  ...    ...    ...       ...   ...   \n",
       "244  2.20   6.944444  11.20  0.10  6.4  13.65   4.05  4.335021   0.0   \n",
       "245  2.48   8.139535  11.40  0.20  6.4  13.50   4.65  4.106990   0.0   \n",
       "246  2.50  23.684211  11.15  0.80  6.2  18.25  14.75  2.481688   0.0   \n",
       "247  2.95  27.368421   7.60  0.50  6.2  16.95  13.95  1.489263   0.0   \n",
       "248  2.10  12.105263  14.00  0.50  6.2  17.25  13.85  1.207845   0.0   \n",
       "\n",
       "          MUCS  0  1  2  3  \n",
       "0     5.234286  0  0  1  0  \n",
       "1    15.912626  0  0  1  0  \n",
       "2     0.000000  0  1  0  0  \n",
       "3     0.200102  0  0  1  0  \n",
       "4     0.254394  0  0  1  0  \n",
       "..         ... .. .. .. ..  \n",
       "244  21.689158  0  0  1  0  \n",
       "245  20.489481  0  0  1  0  \n",
       "246   4.615505  0  0  1  0  \n",
       "247  14.762378  0  0  1  0  \n",
       "248  13.552867  0  0  1  0  \n",
       "\n",
       "[249 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_feature=r\"D:\\文献积累\\文献积累\\盾构隧道\\小论文\\第二篇小论文\\249无HW相关\\地质+盾构特征.xlsx\"\n",
    "data=pd.read_excel(path_feature)\n",
    "data=data.iloc[:,1::]\n",
    "data####将这个数据进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ef15a4a-904a-4057-9629-7ff1873d0e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-2.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0   -0.04\n",
       "1    1.60\n",
       "2   -0.88\n",
       "3   -5.13\n",
       "4   -5.51\n",
       "..    ...\n",
       "244 -2.18\n",
       "245 -3.10\n",
       "246 -5.52\n",
       "247 -2.29\n",
       "248 -2.48\n",
       "\n",
       "[249 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_Smax=r'D:\\文献积累\\文献积累\\盾构隧道\\小论文\\第二篇小论文\\249无HW相关\\沉降值.xlsx'\n",
    "data_Smax=pd.read_excel(path_Smax)\n",
    "data_Smax=data_Smax.iloc[:,1::]\n",
    "data_Smax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b002e7e3-1bce-4127-8153-f6707ffd6212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.04\n",
       "1      1.60\n",
       "2     -0.88\n",
       "3     -5.13\n",
       "4     -5.51\n",
       "       ... \n",
       "244   -2.18\n",
       "245   -3.10\n",
       "246   -5.52\n",
       "247   -2.29\n",
       "248   -2.48\n",
       "Name: 0, Length: 249, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Smax[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b25e893-087d-451a-89b1-45a3245c7931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>Pr</th>\n",
       "      <th>Th</th>\n",
       "      <th>Cp</th>\n",
       "      <th>Gv</th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>MSPT</th>\n",
       "      <th>MDPT</th>\n",
       "      <th>MUCS</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.05</td>\n",
       "      <td>21.875000</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>7.927460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.234286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.60</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0.975344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.912626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.40</td>\n",
       "      <td>23.636364</td>\n",
       "      <td>10.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.35</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.26</td>\n",
       "      <td>25.423729</td>\n",
       "      <td>9.60</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.85</td>\n",
       "      <td>5.55</td>\n",
       "      <td>6.199941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.32</td>\n",
       "      <td>27.678571</td>\n",
       "      <td>11.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.6</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.008770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2.20</td>\n",
       "      <td>6.944444</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.4</td>\n",
       "      <td>13.65</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.335021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.689158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2.48</td>\n",
       "      <td>8.139535</td>\n",
       "      <td>11.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.4</td>\n",
       "      <td>13.50</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.106990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.489481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2.50</td>\n",
       "      <td>23.684211</td>\n",
       "      <td>11.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.25</td>\n",
       "      <td>14.75</td>\n",
       "      <td>2.481688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.615505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2.95</td>\n",
       "      <td>27.368421</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.2</td>\n",
       "      <td>16.95</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1.489263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.762378</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2.10</td>\n",
       "      <td>12.105263</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.2</td>\n",
       "      <td>17.25</td>\n",
       "      <td>13.85</td>\n",
       "      <td>1.207845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.552867</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       To         Pr     Th    Cp   Gv      H      W      MSPT  MDPT  \\\n",
       "0    1.05  21.875000   7.90  0.10  6.5   9.10   5.40  7.927460   0.0   \n",
       "1    2.60   9.230769   9.30  0.26  6.0  12.00   7.05  0.975344   0.0   \n",
       "2    2.40  23.636364  10.20  1.00  6.0  26.35  18.10  0.000000   0.0   \n",
       "3    2.26  25.423729   9.60  0.30  4.5   9.85   5.55  6.199941   0.0   \n",
       "4    3.32  27.678571  11.10  0.50  6.6   9.90   5.50  5.008770   0.0   \n",
       "..    ...        ...    ...   ...  ...    ...    ...       ...   ...   \n",
       "220  2.20   6.944444  11.20  0.10  6.4  13.65   4.05  4.335021   0.0   \n",
       "221  2.48   8.139535  11.40  0.20  6.4  13.50   4.65  4.106990   0.0   \n",
       "222  2.50  23.684211  11.15  0.80  6.2  18.25  14.75  2.481688   0.0   \n",
       "223  2.95  27.368421   7.60  0.50  6.2  16.95  13.95  1.489263   0.0   \n",
       "224  2.10  12.105263  14.00  0.50  6.2  17.25  13.85  1.207845   0.0   \n",
       "\n",
       "          MUCS  0  1  2  3  \n",
       "0     5.234286  0  0  1  0  \n",
       "1    15.912626  0  0  1  0  \n",
       "2     0.000000  0  1  0  0  \n",
       "3     0.200102  0  0  1  0  \n",
       "4     0.254394  0  0  1  0  \n",
       "..         ... .. .. .. ..  \n",
       "220  21.689158  0  0  1  0  \n",
       "221  20.489481  0  0  1  0  \n",
       "222   4.615505  0  0  1  0  \n",
       "223  14.762378  0  0  1  0  \n",
       "224  13.552867  0  0  1  0  \n",
       "\n",
       "[225 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heli_index=np.where(data_Smax[0]>-10)\n",
    "data_safe=data.loc[heli_index].reset_index(drop=True)\n",
    "data_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5d8a2f5-b35a-4027-bd95-e7b76528aa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>Pr</th>\n",
       "      <th>Th</th>\n",
       "      <th>Cp</th>\n",
       "      <th>Gv</th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>MSPT</th>\n",
       "      <th>MDPT</th>\n",
       "      <th>MUCS</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.393005</td>\n",
       "      <td>22.835633</td>\n",
       "      <td>13.537773</td>\n",
       "      <td>1.155429</td>\n",
       "      <td>5.943111</td>\n",
       "      <td>17.910044</td>\n",
       "      <td>12.330622</td>\n",
       "      <td>6.928600</td>\n",
       "      <td>0.218112</td>\n",
       "      <td>7.192193</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.794046</td>\n",
       "      <td>9.473191</td>\n",
       "      <td>3.781754</td>\n",
       "      <td>0.523335</td>\n",
       "      <td>0.743519</td>\n",
       "      <td>3.123093</td>\n",
       "      <td>4.335720</td>\n",
       "      <td>8.529426</td>\n",
       "      <td>0.701355</td>\n",
       "      <td>8.318171</td>\n",
       "      <td>0.147734</td>\n",
       "      <td>0.185592</td>\n",
       "      <td>0.278673</td>\n",
       "      <td>0.161466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>3.462160</td>\n",
       "      <td>4.723034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.869064</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>9.550000</td>\n",
       "      <td>1.135484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.370000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.210280</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>11.490000</td>\n",
       "      <td>3.643565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.601208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.956417</td>\n",
       "      <td>29.411765</td>\n",
       "      <td>15.672586</td>\n",
       "      <td>1.558771</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>20.700000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>7.887535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.997713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>26.350000</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>32.292932</td>\n",
       "      <td>4.181287</td>\n",
       "      <td>31.615726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               To          Pr          Th          Cp          Gv           H  \\\n",
       "count  225.000000  225.000000  225.000000  225.000000  225.000000  225.000000   \n",
       "mean     2.393005   22.835633   13.537773    1.155429    5.943111   17.910044   \n",
       "std      0.794046    9.473191    3.781754    0.523335    0.743519    3.123093   \n",
       "min      0.740000    3.462160    4.723034    0.000000    4.000000    9.100000   \n",
       "25%      1.869064   15.000000   10.900000    0.900000    5.700000   15.700000   \n",
       "50%      2.370000   25.000000   13.000000    1.210280    6.000000   17.250000   \n",
       "75%      2.956417   29.411765   15.672586    1.558771    6.400000   20.700000   \n",
       "max      4.300000   45.833333   24.200000    2.500000    7.900000   26.350000   \n",
       "\n",
       "                W        MSPT        MDPT        MUCS           0           1  \\\n",
       "count  225.000000  225.000000  225.000000  225.000000  225.000000  225.000000   \n",
       "mean    12.330622    6.928600    0.218112    7.192193    0.022222    0.035556   \n",
       "std      4.335720    8.529426    0.701355    8.318171    0.147734    0.185592   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      9.550000    1.135484    0.000000    0.211027    0.000000    0.000000   \n",
       "50%     11.490000    3.643565    0.000000    3.601208    0.000000    0.000000   \n",
       "75%     15.750000    7.887535    0.000000   14.997713    0.000000    0.000000   \n",
       "max     20.300000   32.292932    4.181287   31.615726    1.000000    1.000000   \n",
       "\n",
       "                2           3  \n",
       "count  225.000000  225.000000  \n",
       "mean     0.915556    0.026667  \n",
       "std      0.278673    0.161466  \n",
       "min      0.000000    0.000000  \n",
       "25%      1.000000    0.000000  \n",
       "50%      1.000000    0.000000  \n",
       "75%      1.000000    0.000000  \n",
       "max      1.000000    1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_safe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3783c93e-4960-42c9-b68b-ee4bec68a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data_safe.iloc[:,:5].values\n",
    "X=data_safe.iloc[:,5::].values\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=656)#838"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55778e6f-bb8e-43ad-b5a3-2e76dd1865ed",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "26656586-4823-48ce-93c3-eb0d05b1a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在交叉验证中验证的最好结果： 0.20372023685639568\n",
      "最好的参数模型： DecisionTreeRegressor(criterion='poisson', max_depth=5, min_samples_split=50,\n",
      "                      random_state=10)\n",
      "==================================================\n",
      "最佳模型测试集评估:\n",
      "整体R²分数: 0.3391\n",
      "整体均方根误差(RMSE): 2.7862\n",
      "整体均方根误差(mae): 1.6624\n",
      "\n",
      "各维度详细性能:\n",
      "输出维度 1 => R²: 0.1762, RMSE: 0.6626, MAE: 0.5587\n",
      "输出维度 2 => R²: 0.6298, RMSE: 5.5321, MAE: 4.6934\n",
      "输出维度 3 => R²: 0.4794, RMSE: 2.6779, MAE: 2.2317\n",
      "输出维度 4 => R²: 0.2021, RMSE: 0.4426, MAE: 0.3319\n",
      "输出维度 5 => R²: 0.2078, RMSE: 0.6355, MAE: 0.4959\n",
      "--------------------\n",
      "平均性能 => R²: 0.3391, RMSE: 2.7862, MAE: 1.6624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "estimator = DecisionTreeRegressor()#n_estimators=14, max_depth=21, random_state=298\n",
    "param_dict = {\"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "              \"min_samples_split\":[10,50,100,200,300], \n",
    "              \"random_state\":[3,10, 100,150],\n",
    "              \"max_depth\":[1,5,10,15,20]}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict, cv=5)#\"n_estimators\": [50,100,150,200,250,300,350,400,420,450,500],\n",
    "estimator.fit(X_train,Y_train)\n",
    "\n",
    "# 评估模型效果\n",
    "print(\"在交叉验证中验证的最好结果：\", estimator.best_score_)\n",
    "print(\"最好的参数模型：\", estimator.best_estimator_)\n",
    "best_model = estimator.best_estimator_\n",
    "Y_pred = best_model.predict(X_test)\n",
    "val_pred= best_model.predict(data_val)\n",
    "# 评估指标\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 整体评估\n",
    "r2_overall = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "mse_overall = mean_squared_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "rmse_overall = np.sqrt(mse_overall)\n",
    "mae_overall = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"=\"*50)\n",
    "print(f\"最佳模型测试集评估:\")\n",
    "print(f\"整体R²分数: {r2_overall:.4f}\")\n",
    "print(f\"整体均方根误差(RMSE): {rmse_overall:.4f}\")\n",
    "print(f\"整体均方根误差(mae): {mae_overall:.4f}\")\n",
    "# # 各维度评估\n",
    "# r2_per_output = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "# rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='uniform_average'))\n",
    "# mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "# print(\"\\n各维度详细性能:\")\n",
    "# for i, (r2, rmse,mae) in enumerate(zip(r2_per_output, rmse_per_output,mae_per_output )):\n",
    "#     print(f\"输出维度 {i+1} => R²: {r2:.4f}, RMSE: {rmse:.4f},MAE:{mae:.4f}\")\n",
    "# print(\"--------------------\")  \n",
    "\n",
    "# For per-dimension metrics (R², RMSE, MAE)\n",
    "r2_per_output = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='raw_values'))\n",
    "mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')  # Changed to raw_values\n",
    "\n",
    "print(\"\\n各维度详细性能:\")\n",
    "for i, (r2, rmse, mae) in enumerate(zip(r2_per_output, rmse_per_output, mae_per_output)):\n",
    "    print(f\"输出维度 {i+1} => R²: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "# For averaged metrics (optional)\n",
    "avg_r2 = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "avg_rmse = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='uniform_average'))\n",
    "avg_mae = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"--------------------\")\n",
    "print(f\"平均性能 => R²: {avg_r2:.4f}, RMSE: {avg_rmse:.4f}, MAE: {avg_mae:.4f}\")\n",
    "\n",
    "# # 整体评估\n",
    "# r2_overall_val = r2_score(label_val, val_pred, multioutput='uniform_average')\n",
    "# mse_overall_val = mean_squared_error(label_val, val_pred, multioutput='uniform_average')\n",
    "# rmse_overall_val = np.sqrt(mse_overall_val)\n",
    "# mae_overall_val = mean_absolute_error(label_val, val_pred, multioutput='uniform_average')\n",
    "# print(\"=\"*50)\n",
    "# print(f\"最佳模型测试集评估:\")\n",
    "# print(f\"整体R²分数: {r2_overall_val:.4f}\")\n",
    "# print(f\"整体均方根误差(RMSE): {rmse_overall_val:.4f}\")\n",
    "# print(f\"整体平均均方根误差(MAE): {mae_overall_val :.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96281aaa-6a84-425c-a043-377cd26b460d",
   "metadata": {},
   "source": [
    "### RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d6044cb0-8ca4-4e8b-9e3f-3cfefb4c051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在交叉验证中验证的最好结果： 0.32471053828575586\n",
      "最好的参数模型： RandomForestRegressor(max_depth=10, n_estimators=200, random_state=50)\n",
      "==================================================\n",
      "最佳模型测试集评估:\n",
      "整体R²分数: 0.5013\n",
      "整体均方根误差(RMSE): 2.4840\n",
      "整体均方根误差(mae): 1.4030\n",
      "\n",
      "各维度详细性能:\n",
      "输出维度 1 => R²: 0.3466, RMSE: 0.5901,MAE:0.4959\n",
      "输出维度 2 => R²: 0.7102, RMSE: 4.8940,MAE:3.8717\n",
      "输出维度 3 => R²: 0.5570, RMSE: 2.4704,MAE:1.9637\n",
      "输出维度 4 => R²: 0.5590, RMSE: 0.3291,MAE:0.2315\n",
      "输出维度 5 => R²: 0.3339, RMSE: 0.5827,MAE:0.4520\n",
      "--------------------\n",
      "==================================================\n",
      "最佳模型测试集评估:\n",
      "整体R²分数: -2.0563\n",
      "整体均方根误差(RMSE): 5.0455\n",
      "整体平均均方根误差(MAE): 2.7669\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestRegressor()#n_estimators=14, max_depth=21, random_state=298\n",
    "param_dict = {\"n_estimators\": [50,100,150,200], \"random_state\": [5,10,50, 100],\"max_depth\":[1,5,10,15]}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict, cv=5)\n",
    "estimator.fit(X_train,Y_train)\n",
    "\n",
    "# 评估模型效果\n",
    "print(\"在交叉验证中验证的最好结果：\", estimator.best_score_)\n",
    "print(\"最好的参数模型：\", estimator.best_estimator_)\n",
    "best_model = estimator.best_estimator_\n",
    "Y_pred = best_model.predict(X_test)\n",
    "val_pred=best_model.predict(data_val)\n",
    "# 评估指标\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "r2_overall = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "mse_overall = mean_squared_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "rmse_overall = np.sqrt(mse_overall)\n",
    "mae_overall = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"=\"*50)\n",
    "print(f\"最佳模型测试集评估:\")\n",
    "print(f\"整体R²分数: {r2_overall:.4f}\")\n",
    "print(f\"整体均方根误差(RMSE): {rmse_overall:.4f}\")\n",
    "print(f\"整体均方根误差(mae): {mae_overall:.4f}\")\n",
    "# 各维度评估\n",
    "r2_per_output = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='raw_values'))\n",
    "mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"\\n各维度详细性能:\")\n",
    "for i, (r2, rmse,mae) in enumerate(zip(r2_per_output, rmse_per_output,mae_per_output )):\n",
    "    print(f\"输出维度 {i+1} => R²: {r2:.4f}, RMSE: {rmse:.4f},MAE:{mae:.4f}\")\n",
    "print(\"--------------------\")  \n",
    "\n",
    "\n",
    "# 整体评估\n",
    "r2_overall_val = r2_score(label_val, val_pred, multioutput='uniform_average')\n",
    "mse_overall_val = mean_squared_error(label_val, val_pred, multioutput='uniform_average')\n",
    "rmse_overall_val = np.sqrt(mse_overall_val)\n",
    "\n",
    "mae_overall_val = mean_absolute_error(label_val, val_pred, multioutput='uniform_average')\n",
    "print(\"=\"*50)\n",
    "print(f\"最佳模型测试集评估:\")\n",
    "print(f\"整体R²分数: {r2_overall_val:.4f}\")\n",
    "print(f\"整体均方根误差(RMSE): {rmse_overall_val:.4f}\")\n",
    "print(f\"整体平均均方根误差(MAE): {mae_overall_val :.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ef6c0-7006-424d-8af0-536a15596a5c",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2eb81b76-9be7-4307-9641-0ec2ac4cd3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在交叉验证中验证的最好结果： 0.2923365978550511\n",
      "最好的参数模型： KNeighborsRegressor(n_neighbors=15, weights='distance')\n",
      "==================================================\n",
      "最佳模型测试集评估:\n",
      "整体R²分数: 0.4211\n",
      "整体均方根误差(RMSE): 2.6886\n",
      "整体均方根误差(mae): 1.5504\n",
      "\n",
      "各维度详细性能:\n",
      "输出维度 1 => R²: 0.3137, RMSE: 0.6048,MAE:0.7107\n",
      "输出维度 2 => R²: 0.6615, RMSE: 5.2900,MAE:2.0591\n",
      "输出维度 3 => R²: 0.4717, RMSE: 2.6978,MAE:1.4967\n",
      "输出维度 4 => R²: 0.3626, RMSE: 0.3956,MAE:0.5484\n",
      "输出维度 5 => R²: 0.2959, RMSE: 0.5992,MAE:0.6827\n",
      "--------------------\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "estimator = KNeighborsRegressor()#n_estimators=14, max_depth=21, random_state=298\n",
    "param_dict = {\"n_neighbors\": [5,7,15,16,19,20,27,65,70,75,80,100],\n",
    "              \"weights\" : ['uniform', 'distance']}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict, cv=5)\n",
    "estimator.fit(X_train,Y_train)\n",
    "\n",
    "# 评估模型效果\n",
    "print(\"在交叉验证中验证的最好结果：\", estimator.best_score_)\n",
    "print(\"最好的参数模型：\", estimator.best_estimator_)\n",
    "best_model = estimator.best_estimator_\n",
    "Y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 评估指标\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "r2_overall = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "mse_overall = mean_squared_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "rmse_overall = np.sqrt(mse_overall)\n",
    "mae_overall = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"=\"*50)\n",
    "print(f\"最佳模型测试集评估:\")\n",
    "print(f\"整体R²分数: {r2_overall:.4f}\")\n",
    "print(f\"整体均方根误差(RMSE): {rmse_overall:.4f}\")\n",
    "print(f\"整体均方根误差(mae): {mae_overall:.4f}\")\n",
    "# 各维度评估\n",
    "r2_per_output = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='raw_values'))\n",
    "mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"\\n各维度详细性能:\")\n",
    "for i, (r2, rmse,mae) in enumerate(zip(r2_per_output, rmse_per_output,mae_per_output )):\n",
    "    print(f\"输出维度 {i+1} => R²: {r2:.4f}, RMSE: {rmse:.4f},MAE:{mae:.4f}\")\n",
    "print(\"--------------------\")  \n",
    "\n",
    "# print(\"--------------------\")\n",
    "# train_predict_0=etc.predict(X_train)\n",
    "# print ('训练r^2:',r2_score(Y_train,train_predict_0))\n",
    "# print ('训练均方差',mean_squared_error(Y_train,train_predict_0))\n",
    "# print ('训练绝对差',mean_absolute_error(Y_train,train_predict_0))\n",
    "# print ('训练解释度',explained_variance_score(Y_train,train_predict_0))\n",
    "# print(\"--------------------\")\n",
    "# val_predict_0=etc.predict(X_test)\n",
    "# print ('验证r^2:',r2_score(Y_test,val_predict_0))\n",
    "# print ('验证均方差',mean_squared_error(Y_test,val_predict_0))\n",
    "# print ('验证绝对差',mean_absolute_error(Y_test,val_predict_0))\n",
    "# print ('验证解释度',explained_variance_score(Y_test,val_predict_0))\n",
    "\n",
    "print(\"--------------------\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60fd141-749d-4a23-a4ca-e29dcf942584",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "92041ef0-590b-4bc5-a64b-eaf04d388bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在交叉验证中验证的最好结果： 0.21941070765331067\n",
      "最好的参数模型： LinearRegression()\n",
      "==================================================\n",
      "最佳模型测试集评估:\n",
      "整体R²分数: 0.2693\n",
      "整体均方根误差(RMSE): 3.1727\n",
      "整体均方根误差(mae): 1.8531\n",
      "\n",
      "各维度详细性能:\n",
      "输出维度 1 => R²: 0.2529, RMSE: 0.6310,MAE:0.7046\n",
      "输出维度 2 => R²: 0.5349, RMSE: 6.2004,MAE:2.2632\n",
      "输出维度 3 => R²: 0.2147, RMSE: 3.2890,MAE:1.6647\n",
      "输出维度 4 => R²: 0.3405, RMSE: 0.4024,MAE:0.5660\n",
      "输出维度 5 => R²: 0.0033, RMSE: 0.7128,MAE:0.7450\n",
      "--------------------\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "estimator = LinearRegression()#n_estimators=14, max_depth=21, random_state=298\n",
    "param_dict = {\"fit_intercept\": [True]}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict, cv=5)\n",
    "estimator.fit(X_train,Y_train)\n",
    "\n",
    "# 评估模型效果\n",
    "print(\"在交叉验证中验证的最好结果：\", estimator.best_score_)\n",
    "print(\"最好的参数模型：\", estimator.best_estimator_)\n",
    "best_model = estimator.best_estimator_\n",
    "Y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 评估指标\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "r2_overall = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "mse_overall = mean_squared_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "rmse_overall = np.sqrt(mse_overall)\n",
    "mae_overall = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"=\"*50)\n",
    "print(f\"最佳模型测试集评估:\")\n",
    "print(f\"整体R²分数: {r2_overall:.4f}\")\n",
    "print(f\"整体均方根误差(RMSE): {rmse_overall:.4f}\")\n",
    "print(f\"整体均方根误差(mae): {mae_overall:.4f}\")\n",
    "# 各维度评估\n",
    "r2_per_output = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='raw_values'))\n",
    "mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"\\n各维度详细性能:\")\n",
    "for i, (r2, rmse,mae) in enumerate(zip(r2_per_output, rmse_per_output,mae_per_output )):\n",
    "    print(f\"输出维度 {i+1} => R²: {r2:.4f}, RMSE: {rmse:.4f},MAE:{mae:.4f}\")\n",
    "print(\"--------------------\")  \n",
    "\n",
    "# print(\"--------------------\")\n",
    "# train_predict_0=etc.predict(X_train)\n",
    "# print ('训练r^2:',r2_score(Y_train,train_predict_0))\n",
    "# print ('训练均方差',mean_squared_error(Y_train,train_predict_0))\n",
    "# print ('训练绝对差',mean_absolute_error(Y_train,train_predict_0))\n",
    "# print ('训练解释度',explained_variance_score(Y_train,train_predict_0))\n",
    "# print(\"--------------------\")\n",
    "# val_predict_0=etc.predict(X_test)\n",
    "# print ('验证r^2:',r2_score(Y_test,val_predict_0))\n",
    "# print ('验证均方差',mean_squared_error(Y_test,val_predict_0))\n",
    "# print ('验证绝对差',mean_absolute_error(Y_test,val_predict_0))\n",
    "# print ('验证解释度',explained_variance_score(Y_test,val_predict_0))\n",
    "\n",
    "print(\"--------------------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885ea37-21d6-4d67-b638-8a1944c8d964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3560ae8-1ece-41dc-88f6-a9279dedf4e2",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e30cce46-f63c-4b68-b4b7-55428a367463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目标 1 RMSE: 0.6272\n",
      "目标 1 R2: 0.2617\n",
      "目标 1 MAE: 0.5155\n",
      "目标 2 RMSE: 5.2157\n",
      "目标 2 R2: 0.6709\n",
      "目标 2 MAE: 4.0953\n",
      "目标 3 RMSE: 2.6779\n",
      "目标 3 R2: 0.4794\n",
      "目标 3 MAE: 2.1763\n",
      "目标 4 RMSE: 0.3322\n",
      "目标 4 R2: 0.5506\n",
      "目标 4 MAE: 0.2372\n",
      "目标 5 RMSE: 0.6153\n",
      "目标 5 R2: 0.2575\n",
      "目标 5 MAE: 0.4896\n",
      "1.8936634684577622\n",
      "0.444038761316046\n",
      "1.5027572984720154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 为每个目标定义不同的参数\n",
    "target_params = [\n",
    "    {'C': 1.0, 'epsilon': 0.3, 'gamma': 0.1},   # 目标1\n",
    "    {'C': 7, 'epsilon': 0.4, 'gamma': 0.01},  # 目标2\n",
    "    {'C': 5, 'epsilon': 0.45, 'gamma': 0.1},   # 目标3\n",
    "    {'C': 20, 'epsilon': 0.2, 'gamma': 0.01},   # 目标3\n",
    "    {'C': 20, 'epsilon': 0.4, 'gamma': 0.01}   # 目标3\n",
    "]\n",
    "maevalue=[]\n",
    "models = []\n",
    "predictions = []\n",
    "rmsevalue=[]\n",
    "r2value=[]\n",
    "# 为每个目标单独训练模型\n",
    "for i in range(Y_train.shape[1]):\n",
    "    model = SVR(**target_params[i])\n",
    "    model.fit(X_train, Y_train[:, i])\n",
    "    models.append(model)\n",
    "    pred = model.predict(X_test)\n",
    "    predictions.append(pred)\n",
    "    \n",
    "    # 评估\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test[:, i], pred))\n",
    "    print(f\"目标 {i+1} RMSE: {rmse:.4f}\")\n",
    "    r2_value = r2_score(Y_test[:, i], pred)  # 使用不同的变量名\n",
    "    print(f\"目标 {i+1} R2: {r2_value:.4f}\")\n",
    "    mae=  mean_absolute_error(Y_test[:, i], pred)  # 使用不同的变量名\n",
    "    print(f\"目标 {i+1} MAE: {mae:.4f}\")\n",
    "    rmsevalue.append(rmse)\n",
    "    r2value.append(r2_value)\n",
    "    maevalue.append(mae)\n",
    "    rmse_=pd.Series(rmsevalue)\n",
    "    r2_=pd.Series(r2value)\n",
    "    mae_=pd.Series( maevalue)\n",
    "print(rmse_.mean())\n",
    "print(r2_.mean())\n",
    "print(mae_.mean())\n",
    "# 合并预测结果\n",
    "y_pred = np.column_stack(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c111410-e75f-49a0-ac3d-aea29ac03838",
   "metadata": {},
   "source": [
    "### SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "705baede-b8da-48ad-8a5a-2312e8188dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Target 1: Grid Searching Best Base Model...\n",
      "✅ Best model for Target 1: ExtraTreesRegressor, R² = 0.3160\n",
      "✅ Best model for Target 1: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 10, 'verbose': 0, 'warm_start': False}, R² = 0.3160\n",
      "\n",
      "🔍 Target 2: Grid Searching Best Base Model...\n",
      "✅ Best model for Target 2: ExtraTreesRegressor, R² = 0.2902\n",
      "✅ Best model for Target 2: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 3, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 157, 'verbose': 0, 'warm_start': False}, R² = 0.2902\n",
      "\n",
      "🔍 Target 3: Grid Searching Best Base Model...\n",
      "✅ Best model for Target 3: ExtraTreesRegressor, R² = 0.4402\n",
      "✅ Best model for Target 3: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 157, 'verbose': 0, 'warm_start': False}, R² = 0.4402\n",
      "\n",
      "🔍 Target 4: Grid Searching Best Base Model...\n",
      "✅ Best model for Target 4: SVR, R² = 0.4488\n",
      "✅ Best model for Target 4: {'C': 10.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, R² = 0.4488\n",
      "\n",
      "🔍 Target 5: Grid Searching Best Base Model...\n",
      "✅ Best model for Target 5: RandomForestRegressor, R² = 0.2464\n",
      "✅ Best model for Target 5: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 15, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 550, 'n_jobs': None, 'oob_score': False, 'random_state': 200, 'verbose': 0, 'warm_start': False}, R² = 0.2464\n",
      "\n",
      "=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\n",
      "🎯 Target 1: ExtraTreesRegressor, Final R² = 0.2824\n",
      "🎯 Target 1: ExtraTreesRegressor, Final RMse = 0.6184\n",
      "🎯 Target 1: ExtraTreesRegressor, Final MAe = 0.4968\n",
      "🎯 Target 2: ExtraTreesRegressor, Final R² = 0.6122\n",
      "🎯 Target 2: ExtraTreesRegressor, Final RMse = 5.6620\n",
      "🎯 Target 2: ExtraTreesRegressor, Final MAe = 4.9911\n",
      "🎯 Target 3: ExtraTreesRegressor, Final R² = 0.6323\n",
      "🎯 Target 3: ExtraTreesRegressor, Final RMse = 2.2505\n",
      "🎯 Target 3: ExtraTreesRegressor, Final MAe = 1.8420\n",
      "🎯 Target 4: SVR, Final R² = 0.6385\n",
      "🎯 Target 4: SVR, Final RMse = 0.2979\n",
      "🎯 Target 4: SVR, Final MAe = 0.2363\n",
      "🎯 Target 5: RandomForestRegressor, Final R² = 0.3499\n",
      "🎯 Target 5: RandomForestRegressor, Final RMse = 0.5757\n",
      "🎯 Target 5: RandomForestRegressor, Final MAe = 0.4155\n",
      "0.5030706991673214\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import clone\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "r2_mean_score=[]\n",
    "rmse_mean_score=[]\n",
    "mae_mean_score=[]\n",
    "# ============ 模拟数据 ============\n",
    "kernel = ConstantKernel(constant_value=1.0) * RBF(length_scale=3.0)\n",
    "n_targets = Y_test.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "kf = KFold(n_splits=5, shuffle=True,random_state=175)#,random_state=157\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "\n",
    "# ============ 定义模型池和参数网格 ============\n",
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0, 10.0,20,40,70],\n",
    "        'kernel': ['rbf']\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157],\n",
    "        'max_depth': [3,10],\n",
    "        'random_state':[10,157]\n",
    "    }),\n",
    "    # 'lgb':(lgb.LGBMRegressor(),{\n",
    "    #     'n_estimators': [50,100,157,200,250,450,550],\n",
    "    #    # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'XGB':(xgb.XGBRegressor(),{\n",
    "    #     'n_estimators': [50,100,157,200,250,450,550],\n",
    "    #     'max_depth': [1,5,10,15,20],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "    #     'alpha': [0.1,0.4,0.7, 1.0,5.0],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'KNN':(KNeighborsRegressor(),{\n",
    "    #     \"n_neighbors\": [5,7,12,19,27,50,60],\n",
    "    #     \"weights\" : ['uniform', 'distance']\n",
    "    # }),  \n",
    "}\n",
    "\n",
    "\n",
    " \n",
    "            \n",
    "# ============ Step 1: 为每个目标寻找最优模型，并进行K折交叉预测 ============\n",
    "Y_train_level0 = np.zeros_like(Y_train)\n",
    "Y_test_level0=np.zeros_like(Y_test)\n",
    "best_base_models = []\n",
    "for target_idx in range(n_targets):\n",
    "    print(f\"\\n🔍 Target {target_idx + 1}: Grid Searching Best Base Model...\")\n",
    "    \n",
    "    # 记录最优模型\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "    for name, (model, param_grid) in model_pool.items():\n",
    "        grid = GridSearchCV(clone(model), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(pd.DataFrame(X_train), pd.DataFrame(Y_train[:, target_idx]))\n",
    "        if grid.best_score_ > best_score:\n",
    "            best_score = grid.best_score_\n",
    "            best_model = grid.best_estimator_\n",
    "            params = best_model.get_params()\n",
    "    best_base_models.append(clone(best_model))\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {best_model.__class__.__name__}, R² = {best_score:.4f}\")\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {params}, R² = {best_score:.4f}\")\n",
    "    # K折获取Level-0预测\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "    Y_train_level0[:, target_idx] = preds\n",
    "\n",
    "    \n",
    "    last_test_preds=[]\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "        preds_test= model.predict(X_test)\n",
    "        last_test_preds.append(preds_test)\n",
    "    Y_train_level0[:,target_idx] = preds\n",
    "    Y_test_level0[:,target_idx]=np.mean(np.column_stack(last_test_preds), axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# ============ Step 2: 使用Level-0模型对测试集预测 ============\n",
    "Y_test_level0 = np.zeros_like(Y_test)\n",
    "for target_idx in range(n_targets):\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train, Y_train[:, target_idx])\n",
    "    Y_test_level0[:, target_idx] = model.predict(X_test)\n",
    "\n",
    "# ============ Step 3: 每个目标构建Stacked模型 ============\n",
    "final_models = []\n",
    "print(\"\\n=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\")\n",
    "for target_idx in range(n_targets):\n",
    "    other_idx = [i for i in range(n_targets) if i != target_idx]\n",
    "    X_train_ext = np.hstack([X_train, Y_train_level0[:, other_idx]])\n",
    "    X_test_ext = np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "\n",
    "    # 使用与该目标最佳模型相同类型进行训练\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train_ext, Y_train[:, target_idx])\n",
    "    y_pred = model.predict(X_test_ext)\n",
    "\n",
    "    r2 = r2_score(Y_test[:, target_idx], y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(Y_test[:, target_idx], y_pred))\n",
    "    mae=mean_absolute_error(Y_test[:, target_idx], y_pred)\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final R² = {r2:.4f}\")\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final RMse = {rmse:.4f}\")\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final MAe = {mae:.4f}\")\n",
    "    final_models.append(model)\n",
    "    r2_mean_score.append(r2)\n",
    "    rmse_mean_score.append(rmse)\n",
    "    mae_mean_score.append(mae)\n",
    "    \n",
    "print(pd.Series(r2_mean_score).mean())\n",
    "print(pd.Series(mse_mean_score).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c5deb39-7904-4f35-857f-4ced594afef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Target 1: Grid Searching Best Base Model...\n",
      "✅ Model rf selected for Target 1\n",
      "✅ Model gbr selected for Target 1\n",
      "✅ Model ridge selected for Target 1\n",
      "✅ Model svr selected for Target 1\n",
      "✅ Model etr selected for Target 1\n",
      "✅ Model lgb selected for Target 1\n",
      "✅ Model XGB selected for Target 1\n",
      "✅ Model GPR selected for Target 1\n",
      "✅ Model KNN selected for Target 1\n",
      "✅ Best model for Target 1: ExtraTreesRegressor, R² = 0.3160\n",
      "\n",
      "🔍 Target 2: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 2, skipping...\n",
      "✅ Best model for Target 2: ExtraTreesRegressor, R² = 0.2902\n",
      "\n",
      "🔍 Target 3: Grid Searching Best Base Model...\n",
      "✅ Model rf selected for Target 3\n",
      "✅ Model gbr selected for Target 3\n",
      "✅ Model ridge selected for Target 3\n",
      "✅ Model svr selected for Target 3\n",
      "✅ Model etr selected for Target 3\n",
      "✅ Model lgb selected for Target 3\n",
      "✅ Model XGB selected for Target 3\n",
      "✅ Model GPR selected for Target 3\n",
      "✅ Model KNN selected for Target 3\n",
      "✅ Best model for Target 3: ExtraTreesRegressor, R² = 0.4402\n",
      "\n",
      "🔍 Target 4: Grid Searching Best Base Model...\n",
      "✅ Model rf selected for Target 4\n",
      "✅ Model gbr selected for Target 4\n",
      "✅ Model ridge selected for Target 4\n",
      "✅ Model svr selected for Target 4\n",
      "✅ Model etr selected for Target 4\n",
      "✅ Model lgb selected for Target 4\n",
      "✅ Model XGB selected for Target 4\n",
      "✅ Model GPR selected for Target 4\n",
      "✅ Model KNN selected for Target 4\n",
      "✅ Best model for Target 4: SVR, R² = 0.4488\n",
      "\n",
      "🔍 Target 5: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 5, skipping...\n",
      "✅ Best model for Target 5: RandomForestRegressor, R² = 0.2464\n",
      "\n",
      "=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\n",
      "🎯 Target 1: ExtraTreesRegressor, Final R² = 0.3249\n",
      "🎯 Target 1: ExtraTreesRegressor, Final Mse = 0.3597\n",
      "🎯 Target 2: ExtraTreesRegressor, Final R² = 0.6180\n",
      "🎯 Target 2: ExtraTreesRegressor, Final Mse = 31.5724\n",
      "🎯 Target 3: ExtraTreesRegressor, Final R² = 0.6541\n",
      "🎯 Target 3: ExtraTreesRegressor, Final Mse = 4.7653\n",
      "🎯 Target 4: SVR, Final R² = 0.6585\n",
      "🎯 Target 4: SVR, Final Mse = 0.0839\n",
      "🎯 Target 5: RandomForestRegressor, Final R² = 0.1438\n",
      "🎯 Target 5: RandomForestRegressor, Final Mse = 0.4365\n",
      "0.4798652777978659\n",
      "7.443558475204263\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import clone\n",
    "r2_mean_score= []\n",
    "mse_mean_score= []\n",
    "# ============ 模拟数据 ============\n",
    "\n",
    "n_targets = Y_test.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "kf = KFold(n_splits=5, shuffle=True,random_state=1)\n",
    "\n",
    "# ============ 定义模型池和参数网格 ============\n",
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0, 10.0,20,40,70],\n",
    "        'kernel': ['rbf']\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157],\n",
    "        'max_depth': [3,10],\n",
    "        'random_state':[10,157]\n",
    "    }),\n",
    "    'lgb':(lgb.LGBMRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "       # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'XGB':(xgb.XGBRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "        'alpha': [0.1,0.4,0.7, 1.0,5.0],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'KNN':(KNeighborsRegressor(),{\n",
    "        \"n_neighbors\": [5,7,12,19,27,50,60],\n",
    "        \"weights\" : ['uniform', 'distance']\n",
    "    }),  \n",
    "}\n",
    "# ============ Step 1: 为每个目标寻找最优模型，并进行K折交叉预测 ============\n",
    "Y_train_level0 = {}\n",
    "Y_train_stacked = {}\n",
    "Y_test_stacked = {}\n",
    "best_base_models = []\n",
    "k_blank={}\n",
    "\n",
    "for target_idx in range(n_targets):\n",
    "    print(f\"\\n🔍 Target {target_idx + 1}: Grid Searching Best Base Model...\")\n",
    "    model_train_preds= []\n",
    "    model_test_preds=[]\n",
    "    # 记录最优模型\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for name, (model, param_grid) in model_pool.items():\n",
    "        grid = GridSearchCV(clone(model), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(X_train, Y_train[:, target_idx])\n",
    "        if grid.best_score_ > best_score:\n",
    "            best_score = grid.best_score_\n",
    "            best_model = grid.best_estimator_\n",
    "            #############################单目标堆叠\n",
    "            \n",
    "        if best_score > 0.3:\n",
    "            print(f\"✅ Model {name} selected for Target {target_idx + 1}\")\n",
    "            model_train_preds.append(best_model.predict(X_train))  # 预测训练集\n",
    "            model_test_preds.append(best_model.predict(X_test))\n",
    "            valid_model_found = True\n",
    "        else:\n",
    "            valid_model_found =None\n",
    "    if valid_model_found == True:\n",
    "        # Y_train_stacked[target_idx] = np.column_stack(model_train_preds)\n",
    "        # Y_test_stacked[target_idx] = np.column_stack(model_test_preds)\n",
    "        Y_train_stacked[target_idx] = np.mean(np.column_stack(model_train_preds), axis=1)  # 生成堆叠特征\n",
    "        Y_test_stacked[target_idx] = np.mean(np.column_stack(model_test_preds), axis=1)\n",
    "        k_blank[target_idx]=0\n",
    "    else:\n",
    "        print(f\"⚠️ No valid model found for Target {target_idx + 1}, skipping...\")\n",
    "        k_blank[target_idx]=1\n",
    "    best_base_models.append(clone(best_model))\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {best_model.__class__.__name__}, R² = {best_score:.4f}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # K折获取Level-0预测\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "    Y_train_level0[target_idx] = preds\n",
    "\n",
    "# ============ Step 2: 使用Level-0模型对测试集预测 ============\n",
    "Y_test_level0 = {}\n",
    "for target_idx in range(n_targets):\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train, Y_train[:, target_idx])\n",
    "    Y_test_level0[target_idx] = model.predict(X_test)\n",
    "\n",
    "# ============ Step 3: 每个目标构建Stacked模型 ============\n",
    "final_models = []\n",
    "print(\"\\n=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\")\n",
    "Y_train_level0=pd.DataFrame(Y_train_level0)\n",
    "Y_test_level0=pd.DataFrame(Y_test_level0)\n",
    "for target_idx in range(n_targets):\n",
    "    other_idx = [i for i in range(n_targets) if i != target_idx]\n",
    "    if k_blank[target_idx]==0:\n",
    "        X_train_ext = np.hstack((pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx]),pd.DataFrame(Y_train_stacked[target_idx])))#np.hstack([X_train, Y_train_level0[:, other_idx]])\n",
    "        X_test_ext = np.hstack((pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx]),pd.DataFrame(Y_test_stacked[target_idx])))#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "    else:\n",
    "        X_train_ext = np.hstack([pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx])])\n",
    "        X_test_ext = np.hstack([pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx])])#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "        \n",
    "        \n",
    "\n",
    "    # 使用与该目标最佳模型相同类型进行训练\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train_ext, Y_train[:,target_idx])\n",
    "    y_pred = model.predict(X_test_ext)\n",
    "\n",
    "    r2 = r2_score(Y_test[:, target_idx], y_pred)\n",
    "    mse=mean_squared_error(Y_test[:, target_idx], y_pred)\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final R² = {r2:.4f}\")\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final Mse = {mse:.4f}\")\n",
    "    final_models.append(model)\n",
    "    r2_mean_score.append(r2)\n",
    "    mse_mean_score.append(mse)\n",
    "\n",
    "    \n",
    "print(pd.Series(r2_mean_score).mean())\n",
    "print(pd.Series(mse_mean_score).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c5b2d-9428-4fa4-858f-9aeaa9c1220c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed9e0fa-5c29-4d1d-99b7-ef64141ca6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def calculate_spearman_corr(X, Y):\n",
    "    \"\"\"\n",
    "    计算斯皮尔曼秩相关系数 (Spearman's rank correlation coefficient)\n",
    "    \n",
    "    参数:\n",
    "    X: 特征矩阵或预测值 (一维数组或列向量)\n",
    "    Y: 目标值向量 (一维数组或列向量)\n",
    "    \n",
    "    返回:\n",
    "    rho: 斯皮尔曼相关系数 (范围: -1 到 1)\n",
    "    \"\"\"\n",
    "    # 确保输入是一维数组\n",
    "    X = X.flatten()\n",
    "    Y = Y.flatten()\n",
    "    \n",
    "    # 计算斯皮尔曼秩相关系数\n",
    "    rho, _ = spearmanr(X, Y)\n",
    "    \n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19892718-5c4e-4a3d-adcd-7d6225aa74a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Target 1: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 1, skipping...\n",
      "✅ Best model for Target 1: ExtraTreesRegressor, R² = 0.3160\n",
      "\n",
      "🔍 Target 2: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 2, skipping...\n",
      "✅ Best model for Target 2: ExtraTreesRegressor, R² = 0.2902\n",
      "\n",
      "🔍 Target 3: Grid Searching Best Base Model...\n",
      "✅ Model etr selected for Target 3\n",
      "✅ Model lgb selected for Target 3\n",
      "✅ Model XGB selected for Target 3\n",
      "✅ Model LR selected for Target 3\n",
      "✅ Best model for Target 3: ExtraTreesRegressor, R² = 0.4402\n",
      "\n",
      "🔍 Target 4: Grid Searching Best Base Model...\n",
      "✅ Model rf selected for Target 4\n",
      "✅ Model gbr selected for Target 4\n",
      "✅ Model ridge selected for Target 4\n",
      "✅ Model svr selected for Target 4\n",
      "✅ Model etr selected for Target 4\n",
      "✅ Model lgb selected for Target 4\n",
      "✅ Model XGB selected for Target 4\n",
      "✅ Model LR selected for Target 4\n",
      "✅ Best model for Target 4: SVR, R² = 0.4488\n",
      "\n",
      "🔍 Target 5: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 5, skipping...\n",
      "✅ Best model for Target 5: RandomForestRegressor, R² = 0.2464\n",
      "\n",
      "=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\n",
      "🎯 Target 1: ExtraTreesRegressor, Final R² = 0.3446\n",
      "🎯 Target 1: ExtraTreesRegressor, Final Mse = 0.3493\n",
      "🎯 Target 2: ExtraTreesRegressor, Final R² = 0.6359\n",
      "🎯 Target 2: ExtraTreesRegressor, Final Mse = 30.0989\n",
      "🎯 Target 3: ExtraTreesRegressor, Final R² = 0.6204\n",
      "🎯 Target 3: ExtraTreesRegressor, Final Mse = 5.2291\n",
      "🎯 Target 4: SVR, Final R² = 0.6046\n",
      "🎯 Target 4: SVR, Final Mse = 0.0971\n",
      "🎯 Target 5: RandomForestRegressor, Final R² = 0.4935\n",
      "🎯 Target 5: RandomForestRegressor, Final Mse = 0.2582\n",
      "0.5398153543837633\n",
      "7.206511251635748\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import clone\n",
    "r2_mean_score= []\n",
    "mse_mean_score= []\n",
    "# ============ 模拟数据 ============\n",
    "\n",
    "n_targets = Y_test.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "kf = KFold(n_splits=5, shuffle=True,random_state=7)\n",
    "\n",
    "# ============ 定义模型池和参数网格 ============\n",
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0, 10.0,20,40,70],\n",
    "        'kernel': ['rbf']\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157],\n",
    "        'max_depth': [3,10],\n",
    "        'random_state':[10,157]\n",
    "    }),\n",
    "    'lgb':(lgb.LGBMRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "       # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'XGB':(xgb.XGBRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'LR':(LinearRegression(),{\n",
    "        \"fit_intercept\": [True]\n",
    "    }),     \n",
    "    # 'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "    #     'alpha': [0.1,0.4,0.7, 1.0,5.0],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'KNN':(KNeighborsRegressor(),{\n",
    "    #     \"n_neighbors\": [5,7,12,19,27,50,60],\n",
    "    #     \"weights\" : ['uniform', 'distance']\n",
    "    # }),  \n",
    "}\n",
    "\n",
    "# ============ Step 1: 为每个目标寻找最优模型，并进行K折交叉预测 ============\n",
    "Y_train_level0 = {}\n",
    "Y_train_stacked = {}\n",
    "Y_test_stacked = {}\n",
    "best_base_models = []\n",
    "k_blank={}\n",
    "\n",
    "for target_idx in range(n_targets):\n",
    "    print(f\"\\n🔍 Target {target_idx + 1}: Grid Searching Best Base Model...\")\n",
    "    model_train_preds= []\n",
    "    model_test_preds=[]\n",
    "    # 记录最优模型\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for name, (model, param_grid) in model_pool.items():\n",
    "        grid = GridSearchCV(clone(model), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(X_train, Y_train[:, target_idx])\n",
    "        if grid.best_score_ > best_score:\n",
    "            best_score = grid.best_score_\n",
    "            best_model = grid.best_estimator_\n",
    "            #############################单目标堆叠\n",
    "        stack_preds_train=np.zeros(n_samples)\n",
    "        stack_preds_test=np.zeros(n_samples)   \n",
    "        if best_score > 0.4:\n",
    "            print(f\"✅ Model {name} selected for Target {target_idx + 1}\")\n",
    "            \n",
    "            \n",
    "            ###########################新增的交叉验证\n",
    "            for train_id, val_id in kf.split(X_train):\n",
    "                model_first = clone(best_model)\n",
    "                model_first.fit(X_train[train_id], Y_train[train_id, target_idx])\n",
    "                stack_preds_train[val_id] =model_first.predict(X_train[val_id])\n",
    "                stack_preds_test =model_first.predict(X_test)\n",
    "                  # 预测训练集\n",
    "            model_test_preds.append(stack_preds_test)             ##################################################################这个地方决定了是最后一折还是所有折的均值\n",
    "            model_train_preds.append(stack_preds_train)\n",
    "            \n",
    "            \n",
    "            # model_train_preds.append(best_model.predict(X_train))  # 预测训练集\n",
    "            # model_test_preds.append(best_model.predict(X_test))\n",
    "            valid_model_found = True\n",
    "        else:\n",
    "            valid_model_found =None\n",
    "    if valid_model_found == True:\n",
    "        # Y_train_stacked[target_idx] = np.column_stack(model_train_preds)\n",
    "        # Y_test_stacked[target_idx] = np.column_stack(model_test_preds)\n",
    "        Y_train_stacked[target_idx] = np.mean(np.column_stack(model_train_preds), axis=1)  # 生成堆叠特征\n",
    "        Y_test_stacked[target_idx] = np.mean(np.column_stack(model_test_preds), axis=1)\n",
    "        k_blank[target_idx]=0\n",
    "    else:\n",
    "        print(f\"⚠️ No valid model found for Target {target_idx + 1}, skipping...\")\n",
    "        k_blank[target_idx]=1\n",
    "    best_base_models.append(clone(best_model))\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {best_model.__class__.__name__}, R² = {best_score:.4f}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # K折获取Level-0预测\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "    Y_train_level0[target_idx] = preds\n",
    "\n",
    "# ============ Step 2: 使用Level-0模型对测试集预测 ============\n",
    "Y_test_level0 = {}\n",
    "for target_idx in range(n_targets):\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train, Y_train[:, target_idx])\n",
    "    Y_test_level0[target_idx] = model.predict(X_test)\n",
    "\n",
    "# ============ Step 3: 每个目标构建Stacked模型 ============\n",
    "final_models = []\n",
    "print(\"\\n=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\")\n",
    "Y_train_level0=pd.DataFrame(Y_train_level0)\n",
    "Y_test_level0=pd.DataFrame(Y_test_level0)\n",
    "for target_idx in range(n_targets):\n",
    "    first_other_idx = [i for i in range(n_targets) if i != target_idx]\n",
    "    \n",
    "    ##############################################################筛选相关性特征\n",
    "    from scipy.stats import spearmanr\n",
    "    other_idx=[]\n",
    "    dcorr_threshold=0.3\n",
    "    for i in (first_other_idx):\n",
    "        dcorr = calculate_spearman_corr(Y_train[:,target_idx], Y_train[:,i])\n",
    "        if abs(dcorr) > dcorr_threshold:\n",
    "            other_idx.append(i)\n",
    "            \n",
    "    if k_blank[target_idx]==0:\n",
    "        X_train_ext = np.hstack((pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx]),pd.DataFrame(Y_train_stacked[target_idx])))#np.hstack([X_train, Y_train_level0[:, other_idx]])\n",
    "        X_test_ext = np.hstack((pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx]),pd.DataFrame(Y_test_stacked[target_idx])))#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "    else:\n",
    "        X_train_ext = np.hstack([pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx])])\n",
    "        X_test_ext = np.hstack([pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx])])#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "        \n",
    "        \n",
    "\n",
    "    # 使用与该目标最佳模型相同类型进行训练\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train_ext, Y_train[:,target_idx])\n",
    "    y_pred = model.predict(X_test_ext)\n",
    "\n",
    "    r2 = r2_score(Y_test[:, target_idx], y_pred)\n",
    "    mse=mean_squared_error(Y_test[:, target_idx], y_pred)\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final R² = {r2:.4f}\")\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final Mse = {mse:.4f}\")\n",
    "    final_models.append(model)\n",
    "    r2_mean_score.append(r2)\n",
    "    mse_mean_score.append(mse)\n",
    "\n",
    "    \n",
    "print(pd.Series(r2_mean_score).mean())\n",
    "print(pd.Series(mse_mean_score).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae1bafec-a743-4012-b1c9-f5868be3cc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Target 1: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 1, skipping...\n",
      "✅ Best model for Target 1: ExtraTreesRegressor, R² = 0.3160\n",
      "✅ Best model for Target 1: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 10, 'verbose': 0, 'warm_start': False}, R² = 0.3160\n",
      "\n",
      "🔍 Target 2: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 2, skipping...\n",
      "✅ Best model for Target 2: ExtraTreesRegressor, R² = 0.2902\n",
      "✅ Best model for Target 2: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 3, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 157, 'verbose': 0, 'warm_start': False}, R² = 0.2902\n",
      "\n",
      "🔍 Target 3: Grid Searching Best Base Model...\n",
      "✅ Model etr selected for Target 3\n",
      "✅ Model lgb selected for Target 3\n",
      "✅ Model XGB selected for Target 3\n",
      "✅ Model LR selected for Target 3\n",
      "✅ Best model for Target 3: ExtraTreesRegressor, R² = 0.4402\n",
      "✅ Best model for Target 3: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 157, 'verbose': 0, 'warm_start': False}, R² = 0.4402\n",
      "\n",
      "🔍 Target 4: Grid Searching Best Base Model...\n",
      "✅ Model rf selected for Target 4\n",
      "✅ Model gbr selected for Target 4\n",
      "✅ Model ridge selected for Target 4\n",
      "✅ Model svr selected for Target 4\n",
      "✅ Model etr selected for Target 4\n",
      "✅ Model lgb selected for Target 4\n",
      "✅ Model XGB selected for Target 4\n",
      "✅ Model LR selected for Target 4\n",
      "✅ Best model for Target 4: SVR, R² = 0.4488\n",
      "✅ Best model for Target 4: {'C': 10.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, R² = 0.4488\n",
      "\n",
      "🔍 Target 5: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 5, skipping...\n",
      "✅ Best model for Target 5: RandomForestRegressor, R² = 0.2464\n",
      "✅ Best model for Target 5: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 15, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 550, 'n_jobs': None, 'oob_score': False, 'random_state': 200, 'verbose': 0, 'warm_start': False}, R² = 0.2464\n",
      "\n",
      "=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\n",
      "🎯 Target 1: ExtraTreesRegressor, Final R² = 0.3446\n",
      "🎯 Target 1: ExtraTreesRegressor, Final Mse = 0.3493\n",
      "🎯 Target 2: ExtraTreesRegressor, Final R² = 0.6359\n",
      "🎯 Target 2: ExtraTreesRegressor, Final Mse = 30.0989\n",
      "🎯 Target 3: ExtraTreesRegressor, Final R² = 0.6181\n",
      "🎯 Target 3: ExtraTreesRegressor, Final Mse = 5.2604\n",
      "🎯 Target 4: SVR, Final R² = 0.6295\n",
      "🎯 Target 4: SVR, Final Mse = 0.0910\n",
      "🎯 Target 5: RandomForestRegressor, Final R² = 0.5100\n",
      "🎯 Target 5: RandomForestRegressor, Final Mse = 0.2498\n",
      "0.54762202209412\n",
      "7.2098718849756125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import clone\n",
    "r2_mean_score= []\n",
    "mse_mean_score= []\n",
    "# ============ 模拟数据 ============\n",
    "\n",
    "n_targets = Y_test.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "kf = KFold(n_splits=5, shuffle=True,random_state=1)\n",
    "\n",
    "# ============ 定义模型池和参数网格 ============\n",
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0, 10.0,20,40,70],\n",
    "        'kernel': ['rbf']\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157],\n",
    "        'max_depth': [3,10],\n",
    "        'random_state':[10,157]\n",
    "    }),\n",
    "    'lgb':(lgb.LGBMRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "       # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'XGB':(xgb.XGBRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'LR':(LinearRegression(),{\n",
    "        \"fit_intercept\": [True]\n",
    "    }),     \n",
    "    # 'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "    #     'alpha': [0.1,0.4,0.7, 1.0,5.0],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'KNN':(KNeighborsRegressor(),{\n",
    "    #     \"n_neighbors\": [5,7,12,19,27,50,60],\n",
    "    #     \"weights\" : ['uniform', 'distance']\n",
    "    # }),  \n",
    "}\n",
    "\n",
    "# ============ Step 1: 为每个目标寻找最优模型，并进行K折交叉预测 ============\n",
    "Y_train_level0 = {}\n",
    "Y_train_stacked = {}\n",
    "Y_test_stacked = {}\n",
    "best_base_models = []\n",
    "k_blank={}\n",
    "\n",
    "for target_idx in range(n_targets):\n",
    "    print(f\"\\n🔍 Target {target_idx + 1}: Grid Searching Best Base Model...\")\n",
    "    model_train_preds= []\n",
    "    model_test_preds=[]\n",
    "    # 记录最优模型\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for name, (model, param_grid) in model_pool.items():\n",
    "        grid = GridSearchCV(clone(model), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(X_train, Y_train[:, target_idx])\n",
    "        if grid.best_score_ > best_score:\n",
    "            best_score = grid.best_score_\n",
    "            best_model = grid.best_estimator_\n",
    "            best_params = best_model.get_params()\n",
    "            #############################单目标堆叠\n",
    "        stack_preds_train=np.zeros(n_samples)\n",
    "        stack_preds_test=np.zeros(n_samples)   \n",
    "        if best_score > 0.4:\n",
    "            print(f\"✅ Model {name} selected for Target {target_idx + 1}\")\n",
    "            \n",
    "            \n",
    "            ###########################新增的交叉验证\n",
    "            for train_id, val_id in kf.split(X_train):\n",
    "                model_first = clone(best_model)\n",
    "                model_first.fit(X_train[train_id], Y_train[train_id, target_idx])\n",
    "                stack_preds_train[val_id] =model_first.predict(X_train[val_id])\n",
    "                stack_preds_test =model_first.predict(X_test)\n",
    "                  # 预测训练集\n",
    "                model_test_preds.append(stack_preds_test)             ##################################################################这个地方决定了是最后一折还是所有折的均值\n",
    "            model_train_preds.append(stack_preds_train)\n",
    "            \n",
    "            \n",
    "            # model_train_preds.append(best_model.predict(X_train))  # 预测训练集\n",
    "            # model_test_preds.append(best_model.predict(X_test))\n",
    "            valid_model_found = True\n",
    "        else:\n",
    "            valid_model_found =None\n",
    "    if valid_model_found == True:\n",
    "        # Y_train_stacked[target_idx] = np.column_stack(model_train_preds)\n",
    "        # Y_test_stacked[target_idx] = np.column_stack(model_test_preds)\n",
    "        Y_train_stacked[target_idx] = np.mean(np.column_stack(model_train_preds), axis=1)  # 生成堆叠特征\n",
    "        Y_test_stacked[target_idx] = np.mean(np.column_stack(model_test_preds), axis=1)\n",
    "        k_blank[target_idx]=0\n",
    "    else:\n",
    "        print(f\"⚠️ No valid model found for Target {target_idx + 1}, skipping...\")\n",
    "        k_blank[target_idx]=1\n",
    "    best_base_models.append(clone(best_model))\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {best_model.__class__.__name__}, R² = {best_score:.4f}\")\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {best_params}, R² = {best_score:.4f}\")\n",
    "    \n",
    "    \n",
    "    last_test_preds=[]\n",
    "    # K折获取Level-0预测\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "        preds_test= model.predict(X_test)                    ########################################交叉验证测试集\n",
    "        last_test_preds.append(preds_test)                   ########################################交叉验证测试集\n",
    "    Y_train_level0[target_idx] = preds\n",
    "    Y_test_level0[target_idx]=np.mean(np.column_stack(last_test_preds), axis=1)     ###############################################3#测试\n",
    "# ============ Step 2: 使用Level-0模型对测试集预测 ============\n",
    "# Y_test_level0 = {}\n",
    "# for target_idx in range(n_targets):\n",
    "#     model = clone(best_base_models[target_idx])\n",
    "#     model.fit(X_train, Y_train[:, target_idx])\n",
    "#     Y_test_level0[target_idx] = model.predict(X_test)\n",
    "\n",
    "# ============ Step 3: 每个目标构建Stacked模型 ============\n",
    "final_models = []\n",
    "print(\"\\n=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\")\n",
    "Y_train_level0=pd.DataFrame(Y_train_level0)\n",
    "Y_test_level0=pd.DataFrame(Y_test_level0)\n",
    "for target_idx in range(n_targets):\n",
    "    first_other_idx = [i for i in range(n_targets) if i != target_idx]\n",
    "    \n",
    "    ##############################################################筛选相关性特征\n",
    "    from scipy.stats import spearmanr\n",
    "    other_idx=[]\n",
    "    dcorr_threshold=0.3\n",
    "    for i in (first_other_idx):\n",
    "        dcorr = calculate_spearman_corr(Y_train[:,target_idx], Y_train[:,i])\n",
    "        if abs(dcorr) > dcorr_threshold:\n",
    "            other_idx.append(i)\n",
    "            \n",
    "    if k_blank[target_idx]==0:\n",
    "        X_train_ext = np.hstack((pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx]),pd.DataFrame(Y_train_stacked[target_idx])))#np.hstack([X_train, Y_train_level0[:, other_idx]])\n",
    "        X_test_ext = np.hstack((pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx]),pd.DataFrame(Y_test_stacked[target_idx])))#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "    else:\n",
    "        X_train_ext = np.hstack([pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx])])\n",
    "        X_test_ext = np.hstack([pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx])])#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "        \n",
    "        \n",
    "\n",
    "    # 使用与该目标最佳模型相同类型进行训练\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train_ext, Y_train[:,target_idx])\n",
    "    y_pred = model.predict(X_test_ext)\n",
    "\n",
    "    r2 = r2_score(Y_test[:, target_idx], y_pred)\n",
    "    mse=mean_squared_error(Y_test[:, target_idx], y_pred)\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final R² = {r2:.4f}\")\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final Mse = {mse:.4f}\")\n",
    "    final_models.append(model)\n",
    "    r2_mean_score.append(r2)\n",
    "    mse_mean_score.append(mse)\n",
    "\n",
    "    \n",
    "print(pd.Series(r2_mean_score).mean())\n",
    "print(pd.Series(mse_mean_score).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2cc86ce-eed4-4b2a-9e59-3fefa034273d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.56587525, 27.68625068, 15.92406704,  0.61991023,  6.15745455],\n",
       "       [ 2.4016207 , 12.2783081 , 10.96333016,  0.85231096,  6.44409091],\n",
       "       [ 2.59786599, 14.14147103, 13.4317349 ,  1.20078156,  6.35779798],\n",
       "       [ 2.87161859, 15.86854508, 14.22296923,  1.29136369,  6.372     ],\n",
       "       [ 2.99164212, 24.2839733 , 11.96011166,  0.81731616,  6.13543418],\n",
       "       [ 2.22880177, 26.44057275, 18.60195637,  1.55361628,  5.01381818],\n",
       "       [ 1.92782893, 26.27255449, 19.87091172,  1.61511247,  6.02974924],\n",
       "       [ 1.88478093, 26.58511154, 16.46445248,  1.58397201,  5.86958788],\n",
       "       [ 3.35070994, 22.27183399, 12.45720511,  0.87010667,  6.32474833],\n",
       "       [ 2.62664456, 14.03075072, 14.59182289,  1.15418647,  5.77995426],\n",
       "       [ 2.81908006, 22.50454241, 11.70870984,  0.9753258 ,  6.0948929 ],\n",
       "       [ 2.20424446, 26.63631299, 17.54187917,  1.59532712,  6.28686061],\n",
       "       [ 1.71794717, 26.65090874, 15.9807092 ,  1.50676   ,  5.43927273],\n",
       "       [ 2.4876445 , 11.18910902, 12.89384282,  0.54988043,  6.07029946],\n",
       "       [ 2.81940427, 23.83792544, 12.58151819,  0.79976254,  6.19067459],\n",
       "       [ 2.44958919, 13.4427251 , 11.59911443,  0.31627489,  5.81810909],\n",
       "       [ 2.94566898, 23.06972271, 11.96362624,  0.86625276,  6.21109436],\n",
       "       [ 2.19364708, 26.83402731, 13.26032   ,  0.84899924,  6.14745455],\n",
       "       [ 2.19413817, 26.40691242, 15.33727536,  1.46945246,  5.30836364],\n",
       "       [ 2.68327005, 10.63722749, 11.40852933,  0.25242723,  6.47654545],\n",
       "       [ 2.07409791, 26.69215388, 17.95664043,  1.51030606,  5.41236364],\n",
       "       [ 1.96174403, 26.77338661, 11.80107028,  1.47186156,  6.21436364],\n",
       "       [ 1.63874943, 26.61698212, 17.40843208,  1.43929924,  5.13254545],\n",
       "       [ 1.35475429, 30.03737559,  9.97604641,  1.64810451,  6.05090909],\n",
       "       [ 2.72307924, 23.12479883, 10.03388019,  0.82108525,  6.31457295],\n",
       "       [ 2.91887354, 24.70424177, 10.92649632,  1.02241971,  6.08936709],\n",
       "       [ 1.68672477, 26.6147671 , 17.65484497,  1.58997247,  5.12981818],\n",
       "       [ 3.00065649, 17.26562922, 12.51976499,  1.01142024,  5.72883596],\n",
       "       [ 3.06823085, 22.82195993, 12.30628973,  0.8165624 ,  6.15886369],\n",
       "       [ 3.06131015, 22.51242939, 12.08886836,  1.05007756,  6.23857025],\n",
       "       [ 2.54555951, 10.18512448, 11.39356213,  0.2738919 ,  6.53272727],\n",
       "       [ 2.53075764, 15.16271903, 10.62734909,  0.56319629,  6.38927273],\n",
       "       [ 1.92211665, 26.643051  , 14.69509084,  1.51420017,  5.13327273],\n",
       "       [ 3.35820994, 21.95727471, 12.43733255,  0.88930807,  6.2754021 ],\n",
       "       [ 2.92672266, 22.47200466, 11.79786771,  1.01638035,  6.04530967],\n",
       "       [ 2.57304998, 12.40196896, 11.56358719,  0.83457824,  6.17619222],\n",
       "       [ 3.33902792, 23.95172742, 10.30743901,  1.11027672,  6.47836708],\n",
       "       [ 1.91955986, 26.57353128, 17.99714264,  1.4758283 ,  5.84545455],\n",
       "       [ 2.19725806, 27.58764372, 13.334     ,  0.76951201,  6.19763636],\n",
       "       [ 2.09931853, 26.64743851, 14.4918186 ,  1.51658365,  5.67990909],\n",
       "       [ 2.12053649, 26.62785438,  9.95527763,  1.53793101,  6.33185628],\n",
       "       [ 2.06983905, 26.36412739, 17.47576392,  1.68026549,  5.95042424],\n",
       "       [ 3.07351662, 18.01329183, 14.22215827,  1.22341614,  5.29756667],\n",
       "       [ 2.97715403, 23.27069228, 12.49000225,  0.79875104,  6.11893556],\n",
       "       [ 2.5452908 , 10.45135155, 11.25165819,  0.37730753,  6.41909091]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_level0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a6387b0-ef22-4327-9632-89c94ea6e9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.46685306, 2.38433532, 2.63950048, 2.83240963, 3.02409805,\n",
       "       2.1082651 , 1.83006342, 1.90281687, 3.4021857 , 2.63956492,\n",
       "       2.88913269, 2.1642137 , 1.80715381, 2.51969858, 2.81450659,\n",
       "       2.4435684 , 2.95228171, 2.25633083, 2.16745069, 2.63687961,\n",
       "       2.12756635, 1.93898402, 1.69628288, 1.41188842, 2.76748448,\n",
       "       2.98144112, 1.67515784, 2.98408226, 3.04202704, 2.99148885,\n",
       "       2.55875191, 2.69348022, 1.92164711, 3.41317846, 2.9156364 ,\n",
       "       2.51046904, 3.36599617, 1.88783276, 2.25741898, 2.15059925,\n",
       "       2.02840017, 2.09943501, 2.98875155, 2.93884115, 2.59721147])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.column_stack(last_test_preds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe2333-8556-4f24-bcdf-5df6683a1662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d47008-fc8d-4302-9143-148e06b56e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54c25835-5910-4868-a48a-340485a23671",
   "metadata": {},
   "source": [
    "#### 优化模型超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c49cd54-14e6-4efc-b7e9-c0614a2361c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Target 1: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 1, skipping...\n",
      "✅ Best model for Target 1: ExtraTreesRegressor, R² = 0.3024\n",
      "✅ Best model for Target 1: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 157, 'n_jobs': None, 'oob_score': False, 'random_state': 157, 'verbose': 0, 'warm_start': False}, R² = 0.3024\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (45,) into shape (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 73>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    134\u001b[0m         last_test_preds\u001b[38;5;241m.\u001b[39mappend(preds_test)                   \u001b[38;5;66;03m########################################交叉验证测试集\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     Y_train_level0[target_idx] \u001b[38;5;241m=\u001b[39m preds\n\u001b[1;32m--> 136\u001b[0m     Y_test_level0[target_idx]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mcolumn_stack(last_test_preds), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)     \u001b[38;5;66;03m###############################################3#测试\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# ============ Step 2: 使用Level-0模型对测试集预测 ============\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Y_test_level0 = {}\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# for target_idx in range(n_targets):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# ============ Step 3: 每个目标构建Stacked模型 ============\u001b[39;00m\n\u001b[0;32m    145\u001b[0m final_models \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (45,) into shape (5,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import clone\n",
    "r2_mean_score= []\n",
    "mse_mean_score= []\n",
    "# ============ 模拟数据 ============\n",
    "\n",
    "n_targets = Y_test.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "kf = KFold(n_splits=5, shuffle=True,random_state=1)\n",
    "\n",
    "# ============ 定义模型池和参数网格 ============\n",
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,150,157,250,450],\n",
    "        'max_depth': [1,15,20],\n",
    "        'random_state':[3,10,100,157,160]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0,5.0,15, 35,87,100],\n",
    "        'kernel': ['rbf'],\n",
    "        # 'epsilon':[0.3] ,         ##############优化参数\n",
    "        # 'gamma':[0.1]               ###########3##优化参数\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [100,157,200],############################\n",
    "        'max_depth': [10,17],\n",
    "        'random_state':[157]\n",
    "    }),\n",
    "    'lgb':(lgb.LGBMRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "       # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'XGB':(xgb.XGBRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'LR':(LinearRegression(),{\n",
    "        \"fit_intercept\": [True]\n",
    "    }),     \n",
    "    # 'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "    #     'alpha': [0.1,0.4,0.7, 1.0,5.0],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'KNN':(KNeighborsRegressor(),{\n",
    "    #     \"n_neighbors\": [5,7,12,19,27,50,60],\n",
    "    #     \"weights\" : ['uniform', 'distance']\n",
    "    # }),  \n",
    "}\n",
    "\n",
    "# ============ Step 1: 为每个目标寻找最优模型，并进行K折交叉预测 ============\n",
    "Y_train_level0 = {}\n",
    "Y_train_stacked = {}\n",
    "Y_test_stacked = {}\n",
    "best_base_models = []\n",
    "k_blank={}\n",
    "\n",
    "for target_idx in range(n_targets):\n",
    "    print(f\"\\n🔍 Target {target_idx + 1}: Grid Searching Best Base Model...\")\n",
    "    model_train_preds= []\n",
    "    model_test_preds=[]\n",
    "    # 记录最优模型\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for name, (model, param_grid) in model_pool.items():\n",
    "        grid = GridSearchCV(clone(model), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(X_train, Y_train[:, target_idx])\n",
    "        if grid.best_score_ > best_score:\n",
    "            best_score = grid.best_score_\n",
    "            best_model = grid.best_estimator_\n",
    "            best_params = best_model.get_params()\n",
    "            #############################单目标堆叠\n",
    "        stack_preds_train=np.zeros(n_samples)\n",
    "        stack_preds_test=np.zeros(n_samples)   \n",
    "        if best_score > 0.4:\n",
    "            print(f\"✅ Model {name} selected for Target {target_idx + 1}\")\n",
    "            \n",
    "            \n",
    "            ###########################新增的交叉验证\n",
    "            for train_id, val_id in kf.split(X_train):\n",
    "                model_first = clone(best_model)\n",
    "                model_first.fit(X_train[train_id], Y_train[train_id, target_idx])\n",
    "                stack_preds_train[val_id] =model_first.predict(X_train[val_id])\n",
    "                stack_preds_test =model_first.predict(X_test)\n",
    "                  # 预测训练集\n",
    "                model_test_preds.append(stack_preds_test)             ##################################################################这个地方决定了是最后一折还是所有折的均值\n",
    "            model_train_preds.append(stack_preds_train)\n",
    "            \n",
    "            \n",
    "            # model_train_preds.append(best_model.predict(X_train))  # 预测训练集\n",
    "            # model_test_preds.append(best_model.predict(X_test))\n",
    "            valid_model_found = True\n",
    "        else:\n",
    "            valid_model_found =None\n",
    "    if valid_model_found == True:\n",
    "        # Y_train_stacked[target_idx] = np.column_stack(model_train_preds)\n",
    "        # Y_test_stacked[target_idx] = np.column_stack(model_test_preds)\n",
    "        Y_train_stacked[target_idx] = np.mean(np.column_stack(model_train_preds), axis=1)  # 生成堆叠特征\n",
    "        Y_test_stacked[target_idx] = np.mean(np.column_stack(model_test_preds), axis=1)\n",
    "        k_blank[target_idx]=0\n",
    "    else:\n",
    "        print(f\"⚠️ No valid model found for Target {target_idx + 1}, skipping...\")\n",
    "        k_blank[target_idx]=1\n",
    "    best_base_models.append(clone(best_model))\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {best_model.__class__.__name__}, R² = {best_score:.4f}\")\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {best_params}, R² = {best_score:.4f}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    last_test_preds=[]\n",
    "    # K折获取Level-0预测\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "        preds_test= model.predict(X_test)                    ########################################交叉验证测试集\n",
    "        last_test_preds.append(preds_test)                   ########################################交叉验证测试集\n",
    "    Y_train_level0[target_idx] = preds\n",
    "    Y_test_level0[target_idx]=np.mean(np.column_stack(last_test_preds), axis=1)     ###############################################3#测试\n",
    "# ============ Step 2: 使用Level-0模型对测试集预测 ============\n",
    "# Y_test_level0 = {}\n",
    "# for target_idx in range(n_targets):\n",
    "#     model = clone(best_base_models[target_idx])\n",
    "#     model.fit(X_train, Y_train[:, target_idx])\n",
    "#     Y_test_level0[target_idx] = model.predict(X_test)\n",
    "\n",
    "# ============ Step 3: 每个目标构建Stacked模型 ============\n",
    "final_models = []\n",
    "print(\"\\n=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\")\n",
    "Y_train_level0=pd.DataFrame(Y_train_level0)\n",
    "Y_test_level0=pd.DataFrame(Y_test_level0)\n",
    "for target_idx in range(n_targets):\n",
    "    first_other_idx = [i for i in range(n_targets) if i != target_idx]\n",
    "    \n",
    "    ##############################################################筛选相关性特征\n",
    "    from scipy.stats import spearmanr\n",
    "    other_idx=[]\n",
    "    dcorr_threshold=0.3\n",
    "    for i in (first_other_idx):\n",
    "        dcorr = calculate_spearman_corr(Y_train[:,target_idx], Y_train[:,i])\n",
    "        if abs(dcorr) > dcorr_threshold:\n",
    "            other_idx.append(i)\n",
    "            \n",
    "    if k_blank[target_idx]==0:\n",
    "        X_train_ext = np.hstack((pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx]),pd.DataFrame(Y_train_stacked[target_idx])))#np.hstack([X_train, Y_train_level0[:, other_idx]])\n",
    "        X_test_ext = np.hstack((pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx]),pd.DataFrame(Y_test_stacked[target_idx])))#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "    else:\n",
    "        X_train_ext = np.hstack([pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx])])\n",
    "        X_test_ext = np.hstack([pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx])])#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "        \n",
    "        \n",
    "\n",
    "    # 使用与该目标最佳模型相同类型进行训练\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train_ext, Y_train[:,target_idx])\n",
    "    y_pred = model.predict(X_test_ext)\n",
    "\n",
    "    r2 = r2_score(Y_test[:, target_idx], y_pred)\n",
    "    mse=mean_squared_error(Y_test[:, target_idx], y_pred)\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final R² = {r2:.4f}\")\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final Mse = {mse:.4f}\")\n",
    "    final_models.append(model)\n",
    "    r2_mean_score.append(r2)\n",
    "    mse_mean_score.append(mse)\n",
    "\n",
    "    \n",
    "print(pd.Series(r2_mean_score).mean())\n",
    "print(pd.Series(mse_mean_score).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d39e9-b33e-48e3-9bbc-65f842b0520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0, 10.0,20,40,70],\n",
    "        'kernel': ['rbf'],\n",
    "        # 'epsilon':[0.3] ,         ##############优化参数\n",
    "        # 'gamma':[0.1]               ###########3##优化参数\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157],\n",
    "        'max_depth': [3,10],\n",
    "        'random_state':[80,157]\n",
    "    }),\n",
    "    'lgb':(lgb.LGBMRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "       # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'XGB':(xgb.XGBRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'LR':(LinearRegression(),{\n",
    "        \"fit_intercept\": [True]\n",
    "    }),     \n",
    "    # 'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "    #     'alpha': [0.1,0.4,0.7, 1.0,5.0],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'KNN':(KNeighborsRegressor(),{\n",
    "    #     \"n_neighbors\": [5,7,12,19,27,50,60],\n",
    "    #     \"weights\" : ['uniform', 'distance']\n",
    "    # }),  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd86f77-e463-463e-b96d-41e2d04f1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157],############################\n",
    "        'max_depth': [3,10],\n",
    "        'random_state':[80,157]\n",
    "    }),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3deffe0-5e62-4c5b-b399-563efce8db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,150,157,250,450,550],\n",
    "        'max_depth': [1,15,20],\n",
    "        'random_state':[3,10,100,160,200]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0, 10.0,20,40,70],\n",
    "        'kernel': ['rbf'],\n",
    "        # 'epsilon':[0.3] ,         ##############优化参数\n",
    "        # 'gamma':[0.1]               ###########3##优化参数\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157,187,200],############################\n",
    "        'max_depth': [3,10],\n",
    "        'random_state':[80,157]\n",
    "    }),\n",
    "    'lgb':(lgb.LGBMRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "       # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'XGB':(xgb.XGBRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'LR':(LinearRegression(),{\n",
    "        \"fit_intercept\": [True]\n",
    "    }),     \n",
    "    # 'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "    #     'alpha': [0.1,0.4,0.7, 1.0,5.0],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'KNN':(KNeighborsRegressor(),{\n",
    "    #     \"n_neighbors\": [5,7,12,19,27,50,60],\n",
    "    #     \"weights\" : ['uniform', 'distance']\n",
    "    # }),  \n",
    "}\n",
    "\n",
    "=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\n",
    "🎯 Target 1: ExtraTreesRegressor, Final R² = 0.3764\n",
    "🎯 Target 1: ExtraTreesRegressor, Final Mse = 0.3323\n",
    "🎯 Target 2: ExtraTreesRegressor, Final R² = 0.6359\n",
    "🎯 Target 2: ExtraTreesRegressor, Final Mse = 30.0989\n",
    "🎯 Target 3: ExtraTreesRegressor, Final R² = 0.6181\n",
    "🎯 Target 3: ExtraTreesRegressor, Final Mse = 5.2604\n",
    "🎯 Target 4: SVR, Final R² = 0.6305\n",
    "🎯 Target 4: SVR, Final Mse = 0.0907\n",
    "🎯 Target 5: RandomForestRegressor, Final R² = 0.5100\n",
    "🎯 Target 5: RandomForestRegressor, Final Mse = 0.2498\n",
    "0.5541863529108786\n",
    "7.206432403348178\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a23f7d-6010-4168-8a56-af7f88cfdc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbf2e1d0-7c1c-41e7-9f5d-d2f24a03accd",
   "metadata": {},
   "source": [
    "## MTR-SLFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6c88102-41bf-4ac1-a36d-7b436f47f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def calculate_spearman_corr(X, Y):\n",
    "    \"\"\"\n",
    "    计算斯皮尔曼秩相关系数 (Spearman's rank correlation coefficient)\n",
    "    \n",
    "    参数:\n",
    "    X: 特征矩阵或预测值 (一维数组或列向量)\n",
    "    Y: 目标值向量 (一维数组或列向量)\n",
    "    \n",
    "    返回:\n",
    "    rho: 斯皮尔曼相关系数 (范围: -1 到 1)\n",
    "    \"\"\"\n",
    "    # 确保输入是一维数组\n",
    "    X = X.flatten()\n",
    "    Y = Y.flatten()\n",
    "    \n",
    "    # 计算斯皮尔曼秩相关系数\n",
    "    rho, _ = spearmanr(X, Y)\n",
    "    \n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "19695ad7-7f45-45ac-9e01-ac38bb1c0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Target 1: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 1, skipping...\n",
      "✅ Best model for Target 1: ExtraTreesRegressor, R² = 0.3024\n",
      "✅ Best model for Target 1: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 157, 'n_jobs': None, 'oob_score': False, 'random_state': 157, 'verbose': 0, 'warm_start': False}, R² = 0.3024\n",
      "\n",
      "🔍 Target 2: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 2, skipping...\n",
      "✅ Best model for Target 2: SVR, R² = 0.2746\n",
      "✅ Best model for Target 2: {'C': 15, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, R² = 0.2746\n",
      "\n",
      "🔍 Target 3: Grid Searching Best Base Model...\n",
      "✅ Model rf selected for Target 3\n",
      "✅ Model gbr selected for Target 3\n",
      "✅ Model ridge selected for Target 3\n",
      "✅ Model svr selected for Target 3\n",
      "✅ Model etr selected for Target 3\n",
      "✅ Model lgb selected for Target 3\n",
      "✅ Model XGB selected for Target 3\n",
      "✅ Model LR selected for Target 3\n",
      "✅ Best model for Target 3: ExtraTreesRegressor, R² = 0.4402\n",
      "✅ Best model for Target 3: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 157, 'verbose': 0, 'warm_start': False}, R² = 0.4402\n",
      "\n",
      "🔍 Target 4: Grid Searching Best Base Model...\n",
      "✅ Model rf selected for Target 4\n",
      "✅ Model gbr selected for Target 4\n",
      "✅ Model ridge selected for Target 4\n",
      "✅ Model svr selected for Target 4\n",
      "✅ Model etr selected for Target 4\n",
      "✅ Model lgb selected for Target 4\n",
      "✅ Model XGB selected for Target 4\n",
      "✅ Model LR selected for Target 4\n",
      "✅ Best model for Target 4: SVR, R² = 0.4509\n",
      "✅ Best model for Target 4: {'C': 15, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, R² = 0.4509\n",
      "\n",
      "🔍 Target 5: Grid Searching Best Base Model...\n",
      "⚠️ No valid model found for Target 5, skipping...\n",
      "✅ Best model for Target 5: RandomForestRegressor, R² = 0.2427\n",
      "✅ Best model for Target 5: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 15, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 247, 'n_jobs': None, 'oob_score': False, 'random_state': 100, 'verbose': 0, 'warm_start': False}, R² = 0.2427\n",
      "\n",
      "=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\n",
      "🎯 Target 1: ExtraTreesRegressor, Final R² = 0.3734\n",
      "🎯 Target 1: ExtraTreesRegressor, Final RMse = 0.5779\n",
      "🎯 Target 1: ExtraTreesRegressor, Final MAE = 0.4620\n",
      "🎯 Target 2: SVR, Final R² = 0.6939\n",
      "🎯 Target 2: SVR, Final RMse = 5.0300\n",
      "🎯 Target 2: SVR, Final MAE = 3.9432\n",
      "🎯 Target 3: ExtraTreesRegressor, Final R² = 0.5889\n",
      "🎯 Target 3: ExtraTreesRegressor, Final RMse = 2.3798\n",
      "🎯 Target 3: ExtraTreesRegressor, Final MAE = 1.9584\n",
      "🎯 Target 4: SVR, Final R² = 0.6502\n",
      "🎯 Target 4: SVR, Final RMse = 0.2931\n",
      "🎯 Target 4: SVR, Final MAE = 0.2390\n",
      "🎯 Target 5: RandomForestRegressor, Final R² = 0.5127\n",
      "🎯 Target 5: RandomForestRegressor, Final RMse = 0.4984\n",
      "🎯 Target 5: RandomForestRegressor, Final MAE = 0.3419\n",
      "0.563815479932928\n",
      "1.7558333198597427\n",
      "1.3889021005243376\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import clone\n",
    "r2_mean_score= []\n",
    "rmse_mean_score= []\n",
    "mae_mean_score=[]\n",
    "# ============ 模拟数据 ============\n",
    "\n",
    "n_targets = Y_test.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "kf = KFold(n_splits=5, shuffle=True,random_state=1)\n",
    "second_test_predictions=[]\n",
    "\n",
    "# ============ 定义模型池和参数网格 ============\n",
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,100,137,247,359,400],\n",
    "        'max_depth': [1,15],\n",
    "        'random_state':[7,12,18,26,74,100]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0,5.0,15, 35,87,100],\n",
    "        'kernel': ['rbf'],\n",
    "        # 'epsilon':[0.3] ,         ##############优化参数\n",
    "        # 'gamma':[0.1]               ###########3##优化参数\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157],############################\n",
    "        'max_depth': [10,17],\n",
    "        'random_state':[157]\n",
    "    }),\n",
    "    'lgb':(lgb.LGBMRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "       # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'XGB':(xgb.XGBRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'LR':(LinearRegression(),{\n",
    "        \"fit_intercept\": [True]\n",
    "    }),     \n",
    "    # 'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "    #     'alpha': [0.1,0.4,0.7, 1.0,5.0],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'KNN':(KNeighborsRegressor(),{\n",
    "    #     \"n_neighbors\": [5,7,12,19,27,50,60],\n",
    "    #     \"weights\" : ['uniform', 'distance']\n",
    "    # }),  \n",
    "}\n",
    "\n",
    "# ============ Step 1: 为每个目标寻找最优模型，并进行K折交叉预测 ============\n",
    "Y_train_level0 = {}\n",
    "Y_train_stacked = {}\n",
    "Y_test_stacked = {}\n",
    "best_base_models = []\n",
    "k_blank={}\n",
    "\n",
    "for target_idx in range(n_targets):\n",
    "    print(f\"\\n🔍 Target {target_idx + 1}: Grid Searching Best Base Model...\")\n",
    "    model_train_preds= []\n",
    "    model_test_preds=[]\n",
    "    # 记录最优模型\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for name, (model, param_grid) in model_pool.items():\n",
    "        grid = GridSearchCV(clone(model), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(X_train, Y_train[:, target_idx])\n",
    "        if grid.best_score_ > best_score:\n",
    "            best_score = grid.best_score_\n",
    "            best_model = grid.best_estimator_\n",
    "            best_params = best_model.get_params()\n",
    "            #############################单目标堆叠\n",
    "        stack_preds_train=np.zeros(n_samples)\n",
    "        stack_preds_test=np.zeros(n_samples)   \n",
    "        if best_score > 0.4:\n",
    "            print(f\"✅ Model {name} selected for Target {target_idx + 1}\")\n",
    "            \n",
    "            \n",
    "            ###########################新增的交叉验证\n",
    "            for train_id, val_id in kf.split(X_train):\n",
    "                model_first = clone(best_model)\n",
    "                model_first.fit(X_train[train_id], Y_train[train_id, target_idx])\n",
    "                stack_preds_train[val_id] =model_first.predict(X_train[val_id])\n",
    "                stack_preds_test =model_first.predict(X_test)\n",
    "                  # 预测训练集\n",
    "                model_test_preds.append(stack_preds_test)             ##################################################################这个地方决定了是最后一折还是所有折的均值\n",
    "            model_train_preds.append(stack_preds_train)\n",
    "            \n",
    "            \n",
    "            # model_train_preds.append(best_model.predict(X_train))  # 预测训练集\n",
    "            # model_test_preds.append(best_model.predict(X_test))\n",
    "            valid_model_found = True\n",
    "        else:\n",
    "            valid_model_found =None\n",
    "    if valid_model_found == True:\n",
    "        # Y_train_stacked[target_idx] = np.column_stack(model_train_preds)\n",
    "        # Y_test_stacked[target_idx] = np.column_stack(model_test_preds)\n",
    "        Y_train_stacked[target_idx] = np.mean(np.column_stack(model_train_preds), axis=1)  # 生成堆叠特征\n",
    "        Y_test_stacked[target_idx] = np.mean(np.column_stack(model_test_preds), axis=1)\n",
    "        k_blank[target_idx]=0\n",
    "    else:\n",
    "        print(f\"⚠️ No valid model found for Target {target_idx + 1}, skipping...\")\n",
    "        k_blank[target_idx]=1\n",
    "    best_base_models.append(clone(best_model))\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {best_model.__class__.__name__}, R² = {best_score:.4f}\")\n",
    "    print(f\"✅ Best model for Target {target_idx + 1}: {best_params}, R² = {best_score:.4f}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    last_test_preds=[]\n",
    "    # K折获取Level-0预测\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "        preds_test= model.predict(X_test)                    ########################################交叉验证测试集\n",
    "        last_test_preds.append(preds_test)                   ########################################交叉验证测试集\n",
    "    Y_train_level0[target_idx] = preds\n",
    "    Y_test_level0[target_idx]=np.mean(np.column_stack(last_test_preds), axis=1)     ###############################################3#测试\n",
    "# ============ Step 2: 使用Level-0模型对测试集预测 ============\n",
    "# Y_test_level0 = {}\n",
    "# for target_idx in range(n_targets):\n",
    "#     model = clone(best_base_models[target_idx])\n",
    "#     model.fit(X_train, Y_train[:, target_idx])\n",
    "#     Y_test_level0[target_idx] = model.predict(X_test)\n",
    "\n",
    "# ============ Step 3: 每个目标构建Stacked模型 ============\n",
    "final_models = []\n",
    "print(\"\\n=== Final R² Scores (Stacked Single-Target with Input Expansion) ===\")\n",
    "Y_train_level0=pd.DataFrame(Y_train_level0)\n",
    "Y_test_level0=pd.DataFrame(Y_test_level0)\n",
    "for target_idx in range(n_targets):\n",
    "    first_other_idx = [i for i in range(n_targets) if i != target_idx]\n",
    "    \n",
    "    ##############################################################筛选相关性特征\n",
    "    from scipy.stats import spearmanr\n",
    "    other_idx=[]\n",
    "    dcorr_threshold=0.3\n",
    "    for i in (first_other_idx):\n",
    "        dcorr = calculate_spearman_corr(Y_train[:,target_idx], Y_train[:,i])\n",
    "        if abs(dcorr) > dcorr_threshold:\n",
    "            other_idx.append(i)\n",
    "            \n",
    "    if k_blank[target_idx]==0:\n",
    "        X_train_ext = np.hstack((pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx]),pd.DataFrame(Y_train_stacked[target_idx])))#np.hstack([X_train, Y_train_level0[:, other_idx]])\n",
    "        X_test_ext = np.hstack((pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx]),pd.DataFrame(Y_test_stacked[target_idx])))#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "    else:\n",
    "        X_train_ext = np.hstack([pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx])])\n",
    "        X_test_ext = np.hstack([pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx])])#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "        \n",
    "        \n",
    "\n",
    "    # 使用与该目标最佳模型相同类型进行训练\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train_ext, Y_train[:,target_idx])\n",
    "    y_pred = model.predict(X_test_ext)\n",
    "\n",
    "    r2 = r2_score(Y_test[:, target_idx], y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(Y_test[:, target_idx], y_pred))\n",
    "    mae= mean_absolute_error(Y_test[:, target_idx], y_pred)\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final R² = {r2:.4f}\")\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final RMse = {rmse:.4f}\")\n",
    "    print(f\"🎯 Target {target_idx+1}: {model.__class__.__name__}, Final MAE = {mae:.4f}\")\n",
    "    final_models.append(model)\n",
    "    r2_mean_score.append(r2)\n",
    "    rmse_mean_score.append(rmse)\n",
    "    mae_mean_score.append(mae)\n",
    "    second_test_predictions.append(y_pred)\n",
    "    \n",
    "print(pd.Series(r2_mean_score).mean())\n",
    "print(pd.Series(rmse_mean_score).mean())\n",
    "print(pd.Series(mae_mean_score).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5f491e3-15f8-4691-ba79-8102ff0e76f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.07408907, 6.36644175, 6.48704453, 6.34983806, 6.14202761,\n",
       "       5.3659919 , 5.89676113, 5.80242915, 6.23918604, 6.10712551,\n",
       "       6.14688717, 6.20850202, 5.56234818, 6.11443995, 6.14098201,\n",
       "       6.24469013, 6.20485552, 5.97882527, 4.851417  , 6.41157895,\n",
       "       5.24375843, 6.473583  , 5.10890688, 6.32206478, 6.36508579,\n",
       "       6.08748201, 5.06845479, 5.75312753, 6.16651479, 6.18825404,\n",
       "       6.42827935, 6.28703831, 4.94291498, 6.14467412, 6.09677008,\n",
       "       6.21704903, 6.52496626, 5.72877868, 6.24696356, 4.93684211,\n",
       "       6.47302632, 5.95263158, 5.69625506, 6.09066605, 6.3557085 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42d7ae75-42cd-4ede-9a57-1b5bc2ce0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_predictions=pd.concat([pd.DataFrame(second_test_predictions[0]),pd.DataFrame(second_test_predictions[1]),pd.DataFrame(second_test_predictions[2]),pd.DataFrame(second_test_predictions[3]),pd.DataFrame(second_test_predictions[4])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71858118-d980-4a73-b01a-2ed9d248693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.523413</td>\n",
       "      <td>28.915425</td>\n",
       "      <td>15.634663</td>\n",
       "      <td>0.567767</td>\n",
       "      <td>6.074089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.393692</td>\n",
       "      <td>7.981461</td>\n",
       "      <td>12.109843</td>\n",
       "      <td>0.728701</td>\n",
       "      <td>6.366442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.575933</td>\n",
       "      <td>10.638688</td>\n",
       "      <td>12.228580</td>\n",
       "      <td>1.357412</td>\n",
       "      <td>6.487045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.915589</td>\n",
       "      <td>20.735312</td>\n",
       "      <td>12.682480</td>\n",
       "      <td>1.219412</td>\n",
       "      <td>6.349838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.018139</td>\n",
       "      <td>26.972315</td>\n",
       "      <td>12.279502</td>\n",
       "      <td>0.861160</td>\n",
       "      <td>6.142028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.169157</td>\n",
       "      <td>25.893359</td>\n",
       "      <td>16.596148</td>\n",
       "      <td>1.543185</td>\n",
       "      <td>5.365992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.817884</td>\n",
       "      <td>25.999641</td>\n",
       "      <td>20.731659</td>\n",
       "      <td>1.732881</td>\n",
       "      <td>5.896761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.909677</td>\n",
       "      <td>26.707039</td>\n",
       "      <td>16.652384</td>\n",
       "      <td>1.649612</td>\n",
       "      <td>5.802429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.353078</td>\n",
       "      <td>28.272582</td>\n",
       "      <td>12.327391</td>\n",
       "      <td>0.938323</td>\n",
       "      <td>6.239186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.614739</td>\n",
       "      <td>10.513751</td>\n",
       "      <td>13.243723</td>\n",
       "      <td>1.367530</td>\n",
       "      <td>6.107126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.919880</td>\n",
       "      <td>23.657849</td>\n",
       "      <td>11.476446</td>\n",
       "      <td>1.005249</td>\n",
       "      <td>6.146887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.185550</td>\n",
       "      <td>27.867805</td>\n",
       "      <td>17.284223</td>\n",
       "      <td>1.644785</td>\n",
       "      <td>6.208502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.762732</td>\n",
       "      <td>26.441079</td>\n",
       "      <td>16.819405</td>\n",
       "      <td>1.484156</td>\n",
       "      <td>5.562348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.505024</td>\n",
       "      <td>7.826816</td>\n",
       "      <td>12.547932</td>\n",
       "      <td>0.684825</td>\n",
       "      <td>6.114440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.906973</td>\n",
       "      <td>26.353746</td>\n",
       "      <td>12.326282</td>\n",
       "      <td>0.849979</td>\n",
       "      <td>6.140982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.315991</td>\n",
       "      <td>8.839036</td>\n",
       "      <td>11.788399</td>\n",
       "      <td>0.238757</td>\n",
       "      <td>6.244690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.904503</td>\n",
       "      <td>24.128423</td>\n",
       "      <td>12.123405</td>\n",
       "      <td>0.875658</td>\n",
       "      <td>6.204856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.351975</td>\n",
       "      <td>26.050099</td>\n",
       "      <td>11.453777</td>\n",
       "      <td>0.532454</td>\n",
       "      <td>5.978825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.114548</td>\n",
       "      <td>26.628591</td>\n",
       "      <td>15.749525</td>\n",
       "      <td>1.443950</td>\n",
       "      <td>4.851417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.664942</td>\n",
       "      <td>6.243714</td>\n",
       "      <td>12.016820</td>\n",
       "      <td>0.078075</td>\n",
       "      <td>6.411579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.156815</td>\n",
       "      <td>28.124461</td>\n",
       "      <td>17.748519</td>\n",
       "      <td>1.574272</td>\n",
       "      <td>5.243758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.915788</td>\n",
       "      <td>27.707946</td>\n",
       "      <td>12.203609</td>\n",
       "      <td>1.503752</td>\n",
       "      <td>6.473583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.700630</td>\n",
       "      <td>27.673630</td>\n",
       "      <td>18.028027</td>\n",
       "      <td>1.443137</td>\n",
       "      <td>5.108907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.432960</td>\n",
       "      <td>26.588196</td>\n",
       "      <td>8.545318</td>\n",
       "      <td>1.606958</td>\n",
       "      <td>6.322065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.694013</td>\n",
       "      <td>22.562332</td>\n",
       "      <td>9.618148</td>\n",
       "      <td>0.742642</td>\n",
       "      <td>6.365086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.957696</td>\n",
       "      <td>25.618783</td>\n",
       "      <td>10.840541</td>\n",
       "      <td>0.975918</td>\n",
       "      <td>6.087482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.667456</td>\n",
       "      <td>26.237353</td>\n",
       "      <td>17.364044</td>\n",
       "      <td>1.616185</td>\n",
       "      <td>5.068455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.980152</td>\n",
       "      <td>12.929408</td>\n",
       "      <td>13.318982</td>\n",
       "      <td>1.030669</td>\n",
       "      <td>5.753128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.042754</td>\n",
       "      <td>26.156531</td>\n",
       "      <td>12.327419</td>\n",
       "      <td>0.853170</td>\n",
       "      <td>6.166515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.020750</td>\n",
       "      <td>25.867170</td>\n",
       "      <td>11.957737</td>\n",
       "      <td>1.075159</td>\n",
       "      <td>6.188254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.504736</td>\n",
       "      <td>6.200274</td>\n",
       "      <td>12.206981</td>\n",
       "      <td>0.113891</td>\n",
       "      <td>6.428279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.637431</td>\n",
       "      <td>10.620775</td>\n",
       "      <td>11.306387</td>\n",
       "      <td>0.423484</td>\n",
       "      <td>6.287038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.937419</td>\n",
       "      <td>26.898244</td>\n",
       "      <td>15.413114</td>\n",
       "      <td>1.524694</td>\n",
       "      <td>4.942915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.360021</td>\n",
       "      <td>28.265824</td>\n",
       "      <td>12.390949</td>\n",
       "      <td>0.962754</td>\n",
       "      <td>6.144674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.975067</td>\n",
       "      <td>23.246638</td>\n",
       "      <td>11.368416</td>\n",
       "      <td>1.054696</td>\n",
       "      <td>6.096770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.506270</td>\n",
       "      <td>9.219542</td>\n",
       "      <td>11.458753</td>\n",
       "      <td>0.860757</td>\n",
       "      <td>6.217049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.361085</td>\n",
       "      <td>24.535998</td>\n",
       "      <td>10.662064</td>\n",
       "      <td>1.040273</td>\n",
       "      <td>6.524966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.885331</td>\n",
       "      <td>27.406413</td>\n",
       "      <td>17.672359</td>\n",
       "      <td>1.467968</td>\n",
       "      <td>5.728779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.202081</td>\n",
       "      <td>29.196957</td>\n",
       "      <td>12.701200</td>\n",
       "      <td>0.791110</td>\n",
       "      <td>6.246964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.124657</td>\n",
       "      <td>27.155650</td>\n",
       "      <td>14.251143</td>\n",
       "      <td>1.571123</td>\n",
       "      <td>4.936842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.105911</td>\n",
       "      <td>28.344477</td>\n",
       "      <td>12.007117</td>\n",
       "      <td>1.585334</td>\n",
       "      <td>6.473026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.062661</td>\n",
       "      <td>24.978913</td>\n",
       "      <td>17.186896</td>\n",
       "      <td>1.684771</td>\n",
       "      <td>5.952632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.087014</td>\n",
       "      <td>15.680119</td>\n",
       "      <td>13.301682</td>\n",
       "      <td>1.335252</td>\n",
       "      <td>5.696255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.990958</td>\n",
       "      <td>26.344328</td>\n",
       "      <td>12.165415</td>\n",
       "      <td>0.853130</td>\n",
       "      <td>6.090666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.544001</td>\n",
       "      <td>6.502491</td>\n",
       "      <td>11.828267</td>\n",
       "      <td>0.237803</td>\n",
       "      <td>6.355709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          0          0         0         0\n",
       "0   2.523413  28.915425  15.634663  0.567767  6.074089\n",
       "1   2.393692   7.981461  12.109843  0.728701  6.366442\n",
       "2   2.575933  10.638688  12.228580  1.357412  6.487045\n",
       "3   2.915589  20.735312  12.682480  1.219412  6.349838\n",
       "4   3.018139  26.972315  12.279502  0.861160  6.142028\n",
       "5   2.169157  25.893359  16.596148  1.543185  5.365992\n",
       "6   1.817884  25.999641  20.731659  1.732881  5.896761\n",
       "7   1.909677  26.707039  16.652384  1.649612  5.802429\n",
       "8   3.353078  28.272582  12.327391  0.938323  6.239186\n",
       "9   2.614739  10.513751  13.243723  1.367530  6.107126\n",
       "10  2.919880  23.657849  11.476446  1.005249  6.146887\n",
       "11  2.185550  27.867805  17.284223  1.644785  6.208502\n",
       "12  1.762732  26.441079  16.819405  1.484156  5.562348\n",
       "13  2.505024   7.826816  12.547932  0.684825  6.114440\n",
       "14  2.906973  26.353746  12.326282  0.849979  6.140982\n",
       "15  2.315991   8.839036  11.788399  0.238757  6.244690\n",
       "16  2.904503  24.128423  12.123405  0.875658  6.204856\n",
       "17  2.351975  26.050099  11.453777  0.532454  5.978825\n",
       "18  2.114548  26.628591  15.749525  1.443950  4.851417\n",
       "19  2.664942   6.243714  12.016820  0.078075  6.411579\n",
       "20  2.156815  28.124461  17.748519  1.574272  5.243758\n",
       "21  1.915788  27.707946  12.203609  1.503752  6.473583\n",
       "22  1.700630  27.673630  18.028027  1.443137  5.108907\n",
       "23  1.432960  26.588196   8.545318  1.606958  6.322065\n",
       "24  2.694013  22.562332   9.618148  0.742642  6.365086\n",
       "25  2.957696  25.618783  10.840541  0.975918  6.087482\n",
       "26  1.667456  26.237353  17.364044  1.616185  5.068455\n",
       "27  2.980152  12.929408  13.318982  1.030669  5.753128\n",
       "28  3.042754  26.156531  12.327419  0.853170  6.166515\n",
       "29  3.020750  25.867170  11.957737  1.075159  6.188254\n",
       "30  2.504736   6.200274  12.206981  0.113891  6.428279\n",
       "31  2.637431  10.620775  11.306387  0.423484  6.287038\n",
       "32  1.937419  26.898244  15.413114  1.524694  4.942915\n",
       "33  3.360021  28.265824  12.390949  0.962754  6.144674\n",
       "34  2.975067  23.246638  11.368416  1.054696  6.096770\n",
       "35  2.506270   9.219542  11.458753  0.860757  6.217049\n",
       "36  3.361085  24.535998  10.662064  1.040273  6.524966\n",
       "37  1.885331  27.406413  17.672359  1.467968  5.728779\n",
       "38  2.202081  29.196957  12.701200  0.791110  6.246964\n",
       "39  2.124657  27.155650  14.251143  1.571123  4.936842\n",
       "40  2.105911  28.344477  12.007117  1.585334  6.473026\n",
       "41  2.062661  24.978913  17.186896  1.684771  5.952632\n",
       "42  3.087014  15.680119  13.301682  1.335252  5.696255\n",
       "43  2.990958  26.344328  12.165415  0.853130  6.090666\n",
       "44  2.544001   6.502491  11.828267  0.237803  6.355709"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b201fc31-c860-421e-b0e2-1eb977f92687",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_predictions=np.array(overall_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
