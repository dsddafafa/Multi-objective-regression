{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b5e0f7-72e6-4979-a368-7562e9e63789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgbxgb\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sys\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "################################################kæŠ˜äº¤å‰éªŒè¯çš„ç»“æœ\n",
    "from sklearn.model_selection import train_test_split\n",
    "###########################################################################################PSOä¼˜åŒ–ç®—æ³•\n",
    "# å¿½ç•¥è­¦å‘Š\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# å¯¼å…¥ç²’å­ç¾¤ç®—æ³•\n",
    "from sko.PSO import PSO#########ä¸å¯åŠ çº¦æŸçš„ç®—æ³•\n",
    "import random\n",
    "random.seed(7) \n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error,explained_variance_score,mean_absolute_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3783c93e-4960-42c9-b68b-ee4bec68a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data_safe.iloc[:,:5].values\n",
    "X=data_safe.iloc[:,5::].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a7842-19eb-4338-97ec-b686a77afefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55778e6f-bb8e-43ad-b5a3-2e76dd1865ed",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26656586-4823-48ce-93c3-eb0d05b1a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨äº¤å‰éªŒè¯ä¸­éªŒè¯çš„æœ€å¥½ç»“æœï¼š 0.18104465177603887\n",
      "æœ€å¥½çš„å‚æ•°æ¨¡å‹ï¼š DecisionTreeRegressor(criterion='poisson', max_depth=5, min_samples_split=10,\n",
      "                      random_state=50)\n",
      "==================================================\n",
      "æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\n",
      "æ•´ä½“RÂ²åˆ†æ•°: 0.3639\n",
      "æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): 2.8862\n",
      "æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(mae): 1.6396\n",
      "\n",
      "å„ç»´åº¦è¯¦ç»†æ€§èƒ½:\n",
      "è¾“å‡ºç»´åº¦ 1 => RÂ²: 0.1653, RMSE: 0.6669, MAE: 0.5369\n",
      "è¾“å‡ºç»´åº¦ 2 => RÂ²: 0.6048, RMSE: 5.7155, MAE: 4.6564\n",
      "è¾“å‡ºç»´åº¦ 3 => RÂ²: 0.4190, RMSE: 2.8291, MAE: 2.2648\n",
      "è¾“å‡ºç»´åº¦ 4 => RÂ²: 0.3898, RMSE: 0.3871, MAE: 0.2661\n",
      "è¾“å‡ºç»´åº¦ 5 => RÂ²: 0.2404, RMSE: 0.6223, MAE: 0.4739\n",
      "--------------------\n",
      "å¹³å‡æ€§èƒ½ => RÂ²: 0.3639, RMSE: 2.0442, MAE: 1.6396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "estimator = DecisionTreeRegressor()#n_estimators=14, max_depth=21, random_state=298\n",
    "param_dict = {\"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "              \"min_samples_split\":[10,20,21,27], \n",
    "              \"random_state\":[3,50,70,100,150,200,250],\n",
    "              \"max_depth\":[1,5,10,]}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict, cv=5)#\"n_estimators\": [50,100,150,200,250,300,350,400,420,450,500],\n",
    "estimator.fit(X_train,Y_train)\n",
    "\n",
    "# è¯„ä¼°æ¨¡å‹æ•ˆæœ\n",
    "print(\"åœ¨äº¤å‰éªŒè¯ä¸­éªŒè¯çš„æœ€å¥½ç»“æœï¼š\", estimator.best_score_)\n",
    "print(\"æœ€å¥½çš„å‚æ•°æ¨¡å‹ï¼š\", estimator.best_estimator_)\n",
    "best_model = estimator.best_estimator_\n",
    "Y_pred = best_model.predict(X_test)\n",
    "val_pred= best_model.predict(data_val)\n",
    "# è¯„ä¼°æŒ‡æ ‡\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# æ•´ä½“è¯„ä¼°\n",
    "r2_overall = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "mse_overall = mean_squared_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "rmse_overall = np.sqrt(mse_overall)\n",
    "mae_overall = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"=\"*50)\n",
    "print(f\"æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\")\n",
    "print(f\"æ•´ä½“RÂ²åˆ†æ•°: {r2_overall:.4f}\")\n",
    "print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): {rmse_overall:.4f}\")\n",
    "print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(mae): {mae_overall:.4f}\")\n",
    "# # å„ç»´åº¦è¯„ä¼°\n",
    "# r2_per_output = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "# rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='uniform_average'))\n",
    "# mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "# print(\"\\nå„ç»´åº¦è¯¦ç»†æ€§èƒ½:\")\n",
    "# for i, (r2, rmse,mae) in enumerate(zip(r2_per_output, rmse_per_output,mae_per_output )):\n",
    "#     print(f\"è¾“å‡ºç»´åº¦ {i+1} => RÂ²: {r2:.4f}, RMSE: {rmse:.4f},MAE:{mae:.4f}\")\n",
    "# print(\"--------------------\")  \n",
    "\n",
    "# For per-dimension metrics (RÂ², RMSE, MAE)\n",
    "r2_per_output = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='raw_values'))\n",
    "mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')  # Changed to raw_values\n",
    "\n",
    "print(\"\\nå„ç»´åº¦è¯¦ç»†æ€§èƒ½:\")\n",
    "for i, (r2, rmse, mae) in enumerate(zip(r2_per_output, rmse_per_output, mae_per_output)):\n",
    "    print(f\"è¾“å‡ºç»´åº¦ {i+1} => RÂ²: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "# For averaged metrics (optional)\n",
    "avg_r2 = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "avg_rmse = np.mean(rmse_per_output)\n",
    "avg_mae = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"--------------------\")\n",
    "print(f\"å¹³å‡æ€§èƒ½ => RÂ²: {avg_r2:.4f}, RMSE: {avg_rmse:.4f}, MAE: {avg_mae:.4f}\")\n",
    "\n",
    "# # æ•´ä½“è¯„ä¼°\n",
    "# r2_overall_val = r2_score(label_val, val_pred, multioutput='uniform_average')\n",
    "# mse_overall_val = mean_squared_error(label_val, val_pred, multioutput='uniform_average')\n",
    "# rmse_overall_val = np.sqrt(mse_overall_val)\n",
    "# mae_overall_val = mean_absolute_error(label_val, val_pred, multioutput='uniform_average')\n",
    "# print(\"=\"*50)\n",
    "# print(f\"æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\")\n",
    "# print(f\"æ•´ä½“RÂ²åˆ†æ•°: {r2_overall_val:.4f}\")\n",
    "# print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): {rmse_overall_val:.4f}\")\n",
    "# print(f\"æ•´ä½“å¹³å‡å‡æ–¹æ ¹è¯¯å·®(MAE): {mae_overall_val :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099ed20-4918-4998-b785-894f65d966ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96281aaa-6a84-425c-a043-377cd26b460d",
   "metadata": {},
   "source": [
    "### Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6044cb0-8ca4-4e8b-9e3f-3cfefb4c051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨äº¤å‰éªŒè¯ä¸­éªŒè¯çš„æœ€å¥½ç»“æœï¼š 0.3269008671733439\n",
      "æœ€å¥½çš„å‚æ•°æ¨¡å‹ï¼š RandomForestRegressor(max_depth=15, n_estimators=150, random_state=70)\n",
      "\n",
      "å„ç»´åº¦è¯¦ç»†æ€§èƒ½:\n",
      "è¾“å‡ºç»´åº¦ 1 => RÂ²: 0.3542, RMSE: 0.5867,MAE:0.4855\n",
      "è¾“å‡ºç»´åº¦ 2 => RÂ²: 0.7026, RMSE: 4.9579,MAE:3.9674\n",
      "è¾“å‡ºç»´åº¦ 3 => RÂ²: 0.5552, RMSE: 2.4753,MAE:1.9949\n",
      "è¾“å‡ºç»´åº¦ 4 => RÂ²: 0.5588, RMSE: 0.3292,MAE:0.2258\n",
      "è¾“å‡ºç»´åº¦ 5 => RÂ²: 0.3915, RMSE: 0.5570,MAE:0.4194\n",
      "--------------------\n",
      "==================================================\n",
      "æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\n",
      "æ•´ä½“RÂ²åˆ†æ•°: 0.5125\n",
      "æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): 1.7812\n",
      "æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(mae): 1.4186\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestRegressor()#n_estimators=14, max_depth=21, random_state=298\n",
    "param_dict = {\"n_estimators\": [50,100,150,200,300], \"random_state\": [5,10,50,70, 100],\"max_depth\":[1,5,10,15]}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict, cv=5)\n",
    "estimator.fit(X_train,Y_train)\n",
    "\n",
    "# è¯„ä¼°æ¨¡å‹æ•ˆæœ\n",
    "print(\"åœ¨äº¤å‰éªŒè¯ä¸­éªŒè¯çš„æœ€å¥½ç»“æœï¼š\", estimator.best_score_)\n",
    "print(\"æœ€å¥½çš„å‚æ•°æ¨¡å‹ï¼š\", estimator.best_estimator_)\n",
    "best_model = estimator.best_estimator_\n",
    "Y_pred = best_model.predict(X_test)\n",
    "val_pred=best_model.predict(data_val)\n",
    "# è¯„ä¼°æŒ‡æ ‡\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# å„ç»´åº¦è¯„ä¼°\n",
    "r2_per_output = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='raw_values'))\n",
    "mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"\\nå„ç»´åº¦è¯¦ç»†æ€§èƒ½:\")\n",
    "for i, (r2, rmse,mae) in enumerate(zip(r2_per_output, rmse_per_output,mae_per_output )):\n",
    "    print(f\"è¾“å‡ºç»´åº¦ {i+1} => RÂ²: {r2:.4f}, RMSE: {rmse:.4f},MAE:{mae:.4f}\")\n",
    "print(\"--------------------\")  \n",
    "r2_overall = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "rmse_overall = np.mean(rmse_per_output)\n",
    "mae_overall = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"=\"*50)\n",
    "print(f\"æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\")\n",
    "print(f\"æ•´ä½“RÂ²åˆ†æ•°: {r2_overall:.4f}\")\n",
    "print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): {rmse_overall:.4f}\")\n",
    "print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(mae): {mae_overall:.4f}\")\n",
    "\n",
    "# # æ•´ä½“è¯„ä¼°\n",
    "# r2_overall_val = r2_score(label_val, val_pred, multioutput='uniform_average')\n",
    "# mse_overall_val = mean_squared_error(label_val, val_pred, multioutput='uniform_average')\n",
    "# rmse_overall_val = np.sqrt(mse_overall_val)\n",
    "\n",
    "# mae_overall_val = mean_absolute_error(label_val, val_pred, multioutput='uniform_average')\n",
    "# print(\"=\"*50)\n",
    "# print(f\"æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\")\n",
    "# print(f\"æ•´ä½“RÂ²åˆ†æ•°: {r2_overall_val:.4f}\")\n",
    "# print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): {rmse_overall_val:.4f}\")\n",
    "# print(f\"æ•´ä½“å¹³å‡å‡æ–¹æ ¹è¯¯å·®(MAE): {mae_overall_val :.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ef6c0-7006-424d-8af0-536a15596a5c",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eb81b76-9be7-4307-9641-0ec2ac4cd3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨äº¤å‰éªŒè¯ä¸­éªŒè¯çš„æœ€å¥½ç»“æœï¼š 0.2843013089932803\n",
      "æœ€å¥½çš„å‚æ•°æ¨¡å‹ï¼š KNeighborsRegressor(n_neighbors=10, weights='distance')\n",
      "\n",
      "å„ç»´åº¦è¯¦ç»†æ€§èƒ½:\n",
      "è¾“å‡ºç»´åº¦ 1 => RÂ²: 0.3067, RMSE: 0.6079,MAE:0.5184\n",
      "è¾“å‡ºç»´åº¦ 2 => RÂ²: 0.6422, RMSE: 5.4384,MAE:4.1235\n",
      "è¾“å‡ºç»´åº¦ 3 => RÂ²: 0.4940, RMSE: 2.6402,MAE:2.2024\n",
      "è¾“å‡ºç»´åº¦ 4 => RÂ²: 0.4469, RMSE: 0.3685,MAE:0.2848\n",
      "è¾“å‡ºç»´åº¦ 5 => RÂ²: 0.3346, RMSE: 0.5824,MAE:0.4411\n",
      "--------------------\n",
      "==================================================\n",
      "æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\n",
      "æ•´ä½“RÂ²åˆ†æ•°: 0.4449\n",
      "æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): 1.9275\n",
      "æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(mae): 1.5140\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"D:\\Users\\zhang wenpeng\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\zhang wenpeng\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\zhang wenpeng\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"D:\\Users\\zhang wenpeng\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "estimator = KNeighborsRegressor()#n_estimators=14, max_depth=21, random_state=298\n",
    "param_dict = {\"n_neighbors\": [5,10,110,120,150,160,180],\n",
    "              \"weights\" : ['uniform', 'distance']}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict, cv=5)\n",
    "estimator.fit(X_train,Y_train)\n",
    "\n",
    "# è¯„ä¼°æ¨¡å‹æ•ˆæœ\n",
    "print(\"åœ¨äº¤å‰éªŒè¯ä¸­éªŒè¯çš„æœ€å¥½ç»“æœï¼š\", estimator.best_score_)\n",
    "print(\"æœ€å¥½çš„å‚æ•°æ¨¡å‹ï¼š\", estimator.best_estimator_)\n",
    "best_model = estimator.best_estimator_\n",
    "Y_pred = best_model.predict(X_test)\n",
    "\n",
    "# è¯„ä¼°æŒ‡æ ‡\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# å„ç»´åº¦è¯„ä¼°\n",
    "r2_per_output = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='raw_values'))\n",
    "mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"\\nå„ç»´åº¦è¯¦ç»†æ€§èƒ½:\")\n",
    "for i, (r2, rmse,mae) in enumerate(zip(r2_per_output, rmse_per_output,mae_per_output )):\n",
    "    print(f\"è¾“å‡ºç»´åº¦ {i+1} => RÂ²: {r2:.4f}, RMSE: {rmse:.4f},MAE:{mae:.4f}\")\n",
    "print(\"--------------------\")  \n",
    "r2_overall = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "rmse_overall = np.mean(rmse_per_output)\n",
    "mae_overall = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"=\"*50)\n",
    "print(f\"æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\")\n",
    "print(f\"æ•´ä½“RÂ²åˆ†æ•°: {r2_overall:.4f}\")\n",
    "print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): {rmse_overall:.4f}\")\n",
    "print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(mae): {mae_overall:.4f}\")\n",
    "\n",
    "# print(\"--------------------\")\n",
    "# train_predict_0=etc.predict(X_train)\n",
    "# print ('è®­ç»ƒr^2:',r2_score(Y_train,train_predict_0))\n",
    "# print ('è®­ç»ƒå‡æ–¹å·®',mean_squared_error(Y_train,train_predict_0))\n",
    "# print ('è®­ç»ƒç»å¯¹å·®',mean_absolute_error(Y_train,train_predict_0))\n",
    "# print ('è®­ç»ƒè§£é‡Šåº¦',explained_variance_score(Y_train,train_predict_0))\n",
    "# print(\"--------------------\")\n",
    "# val_predict_0=etc.predict(X_test)\n",
    "# print ('éªŒè¯r^2:',r2_score(Y_test,val_predict_0))\n",
    "# print ('éªŒè¯å‡æ–¹å·®',mean_squared_error(Y_test,val_predict_0))\n",
    "# print ('éªŒè¯ç»å¯¹å·®',mean_absolute_error(Y_test,val_predict_0))\n",
    "# print ('éªŒè¯è§£é‡Šåº¦',explained_variance_score(Y_test,val_predict_0))\n",
    "\n",
    "print(\"--------------------\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60fd141-749d-4a23-a4ca-e29dcf942584",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92041ef0-590b-4bc5-a64b-eaf04d388bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨äº¤å‰éªŒè¯ä¸­éªŒè¯çš„æœ€å¥½ç»“æœï¼š 0.21941070765331067\n",
      "æœ€å¥½çš„å‚æ•°æ¨¡å‹ï¼š LinearRegression()\n",
      "\n",
      "å„ç»´åº¦è¯¦ç»†æ€§èƒ½:\n",
      "è¾“å‡ºç»´åº¦ 1 => RÂ²: 0.2529, RMSE: 0.6310,MAE:0.4965\n",
      "è¾“å‡ºç»´åº¦ 2 => RÂ²: 0.5349, RMSE: 6.2004,MAE:5.1221\n",
      "è¾“å‡ºç»´åº¦ 3 => RÂ²: 0.2147, RMSE: 3.2890,MAE:2.7713\n",
      "è¾“å‡ºç»´åº¦ 4 => RÂ²: 0.3405, RMSE: 0.4024,MAE:0.3204\n",
      "è¾“å‡ºç»´åº¦ 5 => RÂ²: 0.0033, RMSE: 0.7128,MAE:0.5551\n",
      "--------------------\n",
      "==================================================\n",
      "æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\n",
      "æ•´ä½“RÂ²åˆ†æ•°: 0.2693\n",
      "æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): 2.2471\n",
      "æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(mae): 1.8531\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "estimator = LinearRegression()#n_estimators=14, max_depth=21, random_state=298\n",
    "param_dict = {\"fit_intercept\": [True]}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict, cv=5)\n",
    "estimator.fit(X_train,Y_train)\n",
    "\n",
    "# è¯„ä¼°æ¨¡å‹æ•ˆæœ\n",
    "print(\"åœ¨äº¤å‰éªŒè¯ä¸­éªŒè¯çš„æœ€å¥½ç»“æœï¼š\", estimator.best_score_)\n",
    "print(\"æœ€å¥½çš„å‚æ•°æ¨¡å‹ï¼š\", estimator.best_estimator_)\n",
    "best_model = estimator.best_estimator_\n",
    "Y_pred = best_model.predict(X_test)\n",
    "\n",
    "# è¯„ä¼°æŒ‡æ ‡\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# å„ç»´åº¦è¯„ä¼°\n",
    "r2_per_output = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "rmse_per_output = np.sqrt(mean_squared_error(Y_test, Y_pred, multioutput='raw_values'))\n",
    "mae_per_output = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"\\nå„ç»´åº¦è¯¦ç»†æ€§èƒ½:\")\n",
    "for i, (r2, rmse,mae) in enumerate(zip(r2_per_output, rmse_per_output,mae_per_output )):\n",
    "    print(f\"è¾“å‡ºç»´åº¦ {i+1} => RÂ²: {r2:.4f}, RMSE: {rmse:.4f},MAE:{mae:.4f}\")\n",
    "print(\"--------------------\")  \n",
    "r2_overall = r2_score(Y_test, Y_pred, multioutput='uniform_average')\n",
    "rmse_overall = np.mean(rmse_per_output)\n",
    "mae_overall = mean_absolute_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "print(\"=\"*50)\n",
    "print(f\"æœ€ä½³æ¨¡å‹æµ‹è¯•é›†è¯„ä¼°:\")\n",
    "print(f\"æ•´ä½“RÂ²åˆ†æ•°: {r2_overall:.4f}\")\n",
    "print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(RMSE): {rmse_overall:.4f}\")\n",
    "print(f\"æ•´ä½“å‡æ–¹æ ¹è¯¯å·®(mae): {mae_overall:.4f}\")\n",
    "\n",
    "# print(\"--------------------\")\n",
    "# train_predict_0=etc.predict(X_train)\n",
    "# print ('è®­ç»ƒr^2:',r2_score(Y_train,train_predict_0))\n",
    "# print ('è®­ç»ƒå‡æ–¹å·®',mean_squared_error(Y_train,train_predict_0))\n",
    "# print ('è®­ç»ƒç»å¯¹å·®',mean_absolute_error(Y_train,train_predict_0))\n",
    "# print ('è®­ç»ƒè§£é‡Šåº¦',explained_variance_score(Y_train,train_predict_0))\n",
    "# print(\"--------------------\")\n",
    "# val_predict_0=etc.predict(X_test)\n",
    "# print ('éªŒè¯r^2:',r2_score(Y_test,val_predict_0))\n",
    "# print ('éªŒè¯å‡æ–¹å·®',mean_squared_error(Y_test,val_predict_0))\n",
    "# print ('éªŒè¯ç»å¯¹å·®',mean_absolute_error(Y_test,val_predict_0))\n",
    "# print ('éªŒè¯è§£é‡Šåº¦',explained_variance_score(Y_test,val_predict_0))\n",
    "\n",
    "print(\"--------------------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885ea37-21d6-4d67-b638-8a1944c8d964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3560ae8-1ece-41dc-88f6-a9279dedf4e2",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e30cce46-f63c-4b68-b4b7-55428a367463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç›®æ ‡ 1 RMSE: 0.6272\n",
      "ç›®æ ‡ 1 R2: 0.2617\n",
      "ç›®æ ‡ 1 MAE: 0.5155\n",
      "ç›®æ ‡ 2 RMSE: 5.2077\n",
      "ç›®æ ‡ 2 R2: 0.6719\n",
      "ç›®æ ‡ 2 MAE: 4.2102\n",
      "ç›®æ ‡ 3 RMSE: 2.7009\n",
      "ç›®æ ‡ 3 R2: 0.4704\n",
      "ç›®æ ‡ 3 MAE: 2.2170\n",
      "ç›®æ ‡ 4 RMSE: 0.3280\n",
      "ç›®æ ‡ 4 R2: 0.5618\n",
      "ç›®æ ‡ 4 MAE: 0.2669\n",
      "ç›®æ ‡ 5 RMSE: 0.5942\n",
      "ç›®æ ‡ 5 R2: 0.3076\n",
      "ç›®æ ‡ 5 MAE: 0.4498\n",
      "1.8916008708093048\n",
      "0.45469320981338035\n",
      "1.5318812158637236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ä¸ºæ¯ä¸ªç›®æ ‡å®šä¹‰ä¸åŒçš„å‚æ•°\n",
    "target_params = [\n",
    "    {'C': 1.0, 'epsilon': 0.3, 'gamma': 0.1},   # ç›®æ ‡1\n",
    "    {'C': 2, 'epsilon': 0.5, 'gamma': 0.01},  # ç›®æ ‡2\n",
    "    {'C': 5, 'epsilon': 0.7, 'gamma': 0.1},   # ç›®æ ‡3\n",
    "    {'C': 10, 'epsilon': 0.6, 'gamma': 0.01},   # ç›®æ ‡3\n",
    "    {'C': 12, 'epsilon': 0.2, 'gamma': 0.01}   # ç›®æ ‡3\n",
    "]\n",
    "maevalue=[]\n",
    "models = []\n",
    "predictions = []\n",
    "rmsevalue=[]\n",
    "r2value=[]\n",
    "# ä¸ºæ¯ä¸ªç›®æ ‡å•ç‹¬è®­ç»ƒæ¨¡å‹\n",
    "for i in range(Y_train.shape[1]):\n",
    "    model = SVR(**target_params[i])\n",
    "    model.fit(X_train, Y_train[:, i])\n",
    "    models.append(model)\n",
    "    pred = model.predict(X_test)\n",
    "    predictions.append(pred)\n",
    "    \n",
    "    # è¯„ä¼°\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test[:, i], pred))\n",
    "    print(f\"ç›®æ ‡ {i+1} RMSE: {rmse:.4f}\")\n",
    "    r2_value = r2_score(Y_test[:, i], pred)  # ä½¿ç”¨ä¸åŒçš„å˜é‡å\n",
    "    print(f\"ç›®æ ‡ {i+1} R2: {r2_value:.4f}\")\n",
    "    mae=  mean_absolute_error(Y_test[:, i], pred)  # ä½¿ç”¨ä¸åŒçš„å˜é‡å\n",
    "    print(f\"ç›®æ ‡ {i+1} MAE: {mae:.4f}\")\n",
    "    rmsevalue.append(rmse)\n",
    "    r2value.append(r2_value)\n",
    "    maevalue.append(mae)\n",
    "    rmse_=pd.Series(rmsevalue)\n",
    "    r2_=pd.Series(r2value)\n",
    "    mae_=pd.Series( maevalue)\n",
    "print(rmse_.mean())\n",
    "print(r2_.mean())\n",
    "print(mae_.mean())\n",
    "# åˆå¹¶é¢„æµ‹ç»“æœ\n",
    "y_pred = np.column_stack(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ea0906-74ac-40ff-aadd-9b43b147852b",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16e69208-8fc5-4ea4-bdb6-c88ef31b6478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è®­ç»ƒç›®æ ‡ 1 çš„ XGBoost æ¨¡å‹...\n",
      "  -> ç›®æ ‡ 1 RMSE: 0.6361\n",
      "  -> ç›®æ ‡ 1 R2:   0.2407\n",
      "  -> ç›®æ ‡ 1 MAE:  0.5069\n",
      "æ­£åœ¨è®­ç»ƒç›®æ ‡ 2 çš„ XGBoost æ¨¡å‹...\n",
      "  -> ç›®æ ‡ 2 RMSE: 4.7729\n",
      "  -> ç›®æ ‡ 2 R2:   0.7244\n",
      "  -> ç›®æ ‡ 2 MAE:  3.8406\n",
      "æ­£åœ¨è®­ç»ƒç›®æ ‡ 3 çš„ XGBoost æ¨¡å‹...\n",
      "  -> ç›®æ ‡ 3 RMSE: 2.5342\n",
      "  -> ç›®æ ‡ 3 R2:   0.5338\n",
      "  -> ç›®æ ‡ 3 MAE:  2.0952\n",
      "æ­£åœ¨è®­ç»ƒç›®æ ‡ 4 çš„ XGBoost æ¨¡å‹...\n",
      "  -> ç›®æ ‡ 4 RMSE: 0.3795\n",
      "  -> ç›®æ ‡ 4 R2:   0.4135\n",
      "  -> ç›®æ ‡ 4 MAE:  0.2807\n",
      "æ­£åœ¨è®­ç»ƒç›®æ ‡ 5 çš„ XGBoost æ¨¡å‹...\n",
      "  -> ç›®æ ‡ 5 RMSE: 0.6043\n",
      "  -> ç›®æ ‡ 5 R2:   0.2838\n",
      "  -> ç›®æ ‡ 5 MAE:  0.4253\n",
      "------------------------------\n",
      "æ‰€æœ‰ç›®æ ‡çš„å¹³å‡è¡¨ç°ï¼š\n",
      "Mean RMSE: 1.7854\n",
      "Mean R2:   0.4392\n",
      "Mean MAE:  1.4298\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# å‡è®¾ X_train, X_test, Y_train, Y_test å·²ç»å®šä¹‰å¥½äº†\n",
    "\n",
    "# 1. å®šä¹‰ XGBoost å‚æ•°\n",
    "# æ³¨æ„ï¼šSVR çš„ C, epsilon, gamma å‚æ•°ä¸é€‚ç”¨äº XGBoostã€‚\n",
    "# ä¸‹é¢æ˜¯ä¸€ç»„å¸¸è§çš„ XGBoost å‚æ•°ç¤ºä¾‹ï¼Œé’ˆå¯¹æ¯ä¸ªç›®æ ‡ä½ å¯ä»¥å•ç‹¬å¾®è°ƒã€‚\n",
    "# å¸¸ç”¨å‚æ•°è¯´æ˜ï¼š\n",
    "# n_estimators: æ ‘çš„æ•°é‡ (ç±»ä¼¼è¿­ä»£æ¬¡æ•°)\n",
    "# max_depth: æ ‘çš„æ·±åº¦ (æ§åˆ¶æ¨¡å‹å¤æ‚åº¦ï¼Œå¤ªé«˜å®¹æ˜“è¿‡æ‹Ÿåˆ)\n",
    "# learning_rate: å­¦ä¹ ç‡ (è¶Šå°è¶Šç¨³ï¼Œä½†éœ€è¦æ›´å¤šçš„ n_estimators)\n",
    "# objective: å›å½’ä»»åŠ¡é€šå¸¸ç”¨ 'reg:squarederror'\n",
    "target_params = [\n",
    "    {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'random_state': 42},   # ç›®æ ‡1\n",
    "    {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.05, 'random_state': 42},  # ç›®æ ‡2\n",
    "    {'n_estimators': 150, 'max_depth': 4, 'learning_rate': 0.1, 'random_state': 42},   # ç›®æ ‡3\n",
    "    {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.01, 'random_state': 42},  # ç›®æ ‡4\n",
    "    {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'random_state': 42}   # ç›®æ ‡5\n",
    "]\n",
    "\n",
    "maevalue = []\n",
    "models = []\n",
    "predictions = []\n",
    "rmsevalue = []\n",
    "r2value = []\n",
    "\n",
    "# 2. ä¸ºæ¯ä¸ªç›®æ ‡å•ç‹¬è®­ç»ƒ XGBoost æ¨¡å‹\n",
    "for i in range(Y_train.shape[1]):\n",
    "    print(f\"æ­£åœ¨è®­ç»ƒç›®æ ‡ {i+1} çš„ XGBoost æ¨¡å‹...\")\n",
    "    \n",
    "    # å®ä¾‹åŒ–æ¨¡å‹ (ä¼ å…¥å¯¹åº”çš„å‚æ•°)\n",
    "    model = XGBRegressor(**target_params[i], n_jobs=-1) # n_jobs=-1 è°ƒç”¨æ‰€æœ‰CPUæ ¸å¿ƒåŠ é€Ÿ\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    model.fit(X_train, Y_train[:, i])\n",
    "    models.append(model)\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    pred = model.predict(X_test)\n",
    "    predictions.append(pred)\n",
    "    \n",
    "    # è¯„ä¼°\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test[:, i], pred))\n",
    "    r2_value = r2_score(Y_test[:, i], pred)\n",
    "    mae = mean_absolute_error(Y_test[:, i], pred)\n",
    "    \n",
    "    print(f\"  -> ç›®æ ‡ {i+1} RMSE: {rmse:.4f}\")\n",
    "    print(f\"  -> ç›®æ ‡ {i+1} R2:   {r2_value:.4f}\")\n",
    "    print(f\"  -> ç›®æ ‡ {i+1} MAE:  {mae:.4f}\")\n",
    "    \n",
    "    rmsevalue.append(rmse)\n",
    "    r2value.append(r2_value)\n",
    "    maevalue.append(mae)\n",
    "\n",
    "# 3. ç»Ÿè®¡ç»“æœ\n",
    "rmse_ = pd.Series(rmsevalue)\n",
    "r2_ = pd.Series(r2value)\n",
    "mae_ = pd.Series(maevalue)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"æ‰€æœ‰ç›®æ ‡çš„å¹³å‡è¡¨ç°ï¼š\")\n",
    "print(f\"Mean RMSE: {rmse_.mean():.4f}\")\n",
    "print(f\"Mean R2:   {r2_.mean():.4f}\")\n",
    "print(f\"Mean MAE:  {mae_.mean():.4f}\")\n",
    "\n",
    "# 4. åˆå¹¶é¢„æµ‹ç»“æœ\n",
    "y_pred = np.column_stack(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a96487-a913-4bdc-b995-a807a2e53658",
   "metadata": {},
   "source": [
    "## SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "556b69e2-b602-4675-8778-ed2b46324c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Target 1: Grid Searching Best Base Model...\n",
      "âœ… Best model for Target 1: ExtraTreesRegressor, RÂ² = 0.3160\n",
      "âœ… Best model for Target 1: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 10, 'verbose': 0, 'warm_start': False}, RÂ² = 0.3160\n",
      "\n",
      "ğŸ” Target 2: Grid Searching Best Base Model...\n",
      "âœ… Best model for Target 2: ExtraTreesRegressor, RÂ² = 0.2902\n",
      "âœ… Best model for Target 2: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 3, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 157, 'verbose': 0, 'warm_start': False}, RÂ² = 0.2902\n",
      "\n",
      "ğŸ” Target 3: Grid Searching Best Base Model...\n",
      "âœ… Best model for Target 3: ExtraTreesRegressor, RÂ² = 0.4402\n",
      "âœ… Best model for Target 3: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 157, 'verbose': 0, 'warm_start': False}, RÂ² = 0.4402\n",
      "\n",
      "ğŸ” Target 4: Grid Searching Best Base Model...\n",
      "âœ… Best model for Target 4: SVR, RÂ² = 0.4488\n",
      "âœ… Best model for Target 4: {'C': 10.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, RÂ² = 0.4488\n",
      "\n",
      "ğŸ” Target 5: Grid Searching Best Base Model...\n",
      "âœ… Best model for Target 5: RandomForestRegressor, RÂ² = 0.2464\n",
      "âœ… Best model for Target 5: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 15, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 550, 'n_jobs': None, 'oob_score': False, 'random_state': 200, 'verbose': 0, 'warm_start': False}, RÂ² = 0.2464\n",
      "\n",
      "=== Final RÂ² Scores (Stacked Single-Target with Input Expansion) ===\n",
      "ğŸ¯ Target 1: ExtraTreesRegressor, Final RÂ² = 0.2824\n",
      "ğŸ¯ Target 1: ExtraTreesRegressor, Final RMse = 0.6184\n",
      "ğŸ¯ Target 1: ExtraTreesRegressor, Final MAe = 0.4968\n",
      "ğŸ¯ Target 2: ExtraTreesRegressor, Final RÂ² = 0.6122\n",
      "ğŸ¯ Target 2: ExtraTreesRegressor, Final RMse = 5.6620\n",
      "ğŸ¯ Target 2: ExtraTreesRegressor, Final MAe = 4.9911\n",
      "ğŸ¯ Target 3: ExtraTreesRegressor, Final RÂ² = 0.6323\n",
      "ğŸ¯ Target 3: ExtraTreesRegressor, Final RMse = 2.2505\n",
      "ğŸ¯ Target 3: ExtraTreesRegressor, Final MAe = 1.8420\n",
      "ğŸ¯ Target 4: SVR, Final RÂ² = 0.6385\n",
      "ğŸ¯ Target 4: SVR, Final RMse = 0.2979\n",
      "ğŸ¯ Target 4: SVR, Final MAe = 0.2363\n",
      "ğŸ¯ Target 5: RandomForestRegressor, Final RÂ² = 0.3499\n",
      "ğŸ¯ Target 5: RandomForestRegressor, Final RMse = 0.5757\n",
      "ğŸ¯ Target 5: RandomForestRegressor, Final MAe = 0.4155\n",
      "0.5030706991673223\n",
      "1.8809150577935327\n",
      "1.5963483301200276\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score \n",
    "from sklearn.base import clone\n",
    "#import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "r2_mean_score=[]\n",
    "mse_mean_score=[]\n",
    "rmse_mean_score=[]\n",
    "mae_mean_score=[]\n",
    "# ============ æ¨¡æ‹Ÿæ•°æ® ============\n",
    "kernel = ConstantKernel(constant_value=1.0) * RBF(length_scale=3.0)\n",
    "n_targets = Y_test.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "kf = KFold(n_splits=5, shuffle=True,random_state=175)#,random_state=157\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "\n",
    "# ============ å®šä¹‰æ¨¡å‹æ± å’Œå‚æ•°ç½‘æ ¼ ============\n",
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0, 10.0,20,],\n",
    "        'kernel': ['rbf']\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157],\n",
    "        'max_depth': [3,10],\n",
    "        'random_state':[10,157]\n",
    "    }),\n",
    "    # 'lgb':(lgb.LGBMRegressor(),{\n",
    "    #     'n_estimators': [50,100,157,200,250],\n",
    "    #    # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    'XGB':(xgb.XGBRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "        'alpha': [0.1,0.7, 1.0,5.0],\n",
    "        'random_state':[3,10,100,157,200]\n",
    "    # }),  \n",
    "    # 'KNN':(KNeighborsRegressor(),{\n",
    "    #     \"n_neighbors\": [5,7,12,19,60],\n",
    "    #     \"weights\" : ['uniform', 'distance']\n",
    "     })}  \n",
    "#}\n",
    "\n",
    "\n",
    " \n",
    "            \n",
    "# ============ Step 1: ä¸ºæ¯ä¸ªç›®æ ‡å¯»æ‰¾æœ€ä¼˜æ¨¡å‹ï¼Œå¹¶è¿›è¡ŒKæŠ˜äº¤å‰é¢„æµ‹ ============\n",
    "Y_train_level0 = np.zeros_like(Y_train)\n",
    "Y_test_level0=np.zeros_like(Y_test)\n",
    "best_base_models = []\n",
    "for target_idx in range(n_targets):\n",
    "    print(f\"\\nğŸ” Target {target_idx + 1}: Grid Searching Best Base Model...\")\n",
    "    \n",
    "    # è®°å½•æœ€ä¼˜æ¨¡å‹\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "    for name, (model, param_grid) in model_pool.items():\n",
    "        grid = GridSearchCV(clone(model), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(pd.DataFrame(X_train), pd.DataFrame(Y_train[:, target_idx]))\n",
    "        if grid.best_score_ > best_score:\n",
    "            best_score = grid.best_score_\n",
    "            best_model = grid.best_estimator_\n",
    "            params = best_model.get_params()\n",
    "    best_base_models.append(clone(best_model))\n",
    "    print(f\"âœ… Best model for Target {target_idx + 1}: {best_model.__class__.__name__}, RÂ² = {best_score:.4f}\")\n",
    "    print(f\"âœ… Best model for Target {target_idx + 1}: {params}, RÂ² = {best_score:.4f}\")\n",
    "    # KæŠ˜è·å–Level-0é¢„æµ‹\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "    Y_train_level0[:, target_idx] = preds\n",
    "\n",
    "    \n",
    "    last_test_preds=[]\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "        preds_test= model.predict(X_test)\n",
    "        last_test_preds.append(preds_test)\n",
    "    Y_train_level0[:,target_idx] = preds\n",
    "    Y_test_level0[:,target_idx]=np.mean(np.column_stack(last_test_preds), axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# ============ Step 2: ä½¿ç”¨Level-0æ¨¡å‹å¯¹æµ‹è¯•é›†é¢„æµ‹ ============\n",
    "Y_test_level0 = np.zeros_like(Y_test)\n",
    "for target_idx in range(n_targets):\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train, Y_train[:, target_idx])\n",
    "    Y_test_level0[:, target_idx] = model.predict(X_test)\n",
    "\n",
    "# ============ Step 3: æ¯ä¸ªç›®æ ‡æ„å»ºStackedæ¨¡å‹ ============\n",
    "final_models = []\n",
    "print(\"\\n=== Final RÂ² Scores (Stacked Single-Target with Input Expansion) ===\")\n",
    "for target_idx in range(n_targets):\n",
    "    other_idx = [i for i in range(n_targets) if i != target_idx]\n",
    "    X_train_ext = np.hstack([X_train, Y_train_level0[:, other_idx]])\n",
    "    X_test_ext = np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "\n",
    "    # ä½¿ç”¨ä¸è¯¥ç›®æ ‡æœ€ä½³æ¨¡å‹ç›¸åŒç±»å‹è¿›è¡Œè®­ç»ƒ\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train_ext, Y_train[:, target_idx])\n",
    "    y_pred = model.predict(X_test_ext)\n",
    "\n",
    "    r2 = r2_score(Y_test[:, target_idx], y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(Y_test[:, target_idx], y_pred))\n",
    "    mae=mean_absolute_error(Y_test[:, target_idx], y_pred)\n",
    "    print(f\"ğŸ¯ Target {target_idx+1}: {model.__class__.__name__}, Final RÂ² = {r2:.4f}\")\n",
    "    print(f\"ğŸ¯ Target {target_idx+1}: {model.__class__.__name__}, Final RMse = {rmse:.4f}\")\n",
    "    print(f\"ğŸ¯ Target {target_idx+1}: {model.__class__.__name__}, Final MAe = {mae:.4f}\")\n",
    "    final_models.append(model)\n",
    "    r2_mean_score.append(r2)\n",
    "    rmse_mean_score.append(rmse)\n",
    "    mae_mean_score.append(mae)\n",
    "    \n",
    "print(pd.Series(r2_mean_score).mean())\n",
    "print(pd.Series(rmse_mean_score).mean())\n",
    "print(pd.Series(mae_mean_score).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2e1d0-7c1c-41e7-9f5d-d2f24a03accd",
   "metadata": {},
   "source": [
    "## MTR-SLFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6c88102-41bf-4ac1-a36d-7b436f47f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def calculate_spearman_corr(X, Y):\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ–¯çš®å°”æ›¼ç§©ç›¸å…³ç³»æ•° (Spearman's rank correlation coefficient)\n",
    "    \n",
    "    å‚æ•°:\n",
    "    X: ç‰¹å¾çŸ©é˜µæˆ–é¢„æµ‹å€¼ (ä¸€ç»´æ•°ç»„æˆ–åˆ—å‘é‡)\n",
    "    Y: ç›®æ ‡å€¼å‘é‡ (ä¸€ç»´æ•°ç»„æˆ–åˆ—å‘é‡)\n",
    "    \n",
    "    è¿”å›:\n",
    "    rho: æ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•° (èŒƒå›´: -1 åˆ° 1)\n",
    "    \"\"\"\n",
    "    # ç¡®ä¿è¾“å…¥æ˜¯ä¸€ç»´æ•°ç»„\n",
    "    X = X.flatten()\n",
    "    Y = Y.flatten()\n",
    "    \n",
    "    # è®¡ç®—æ–¯çš®å°”æ›¼ç§©ç›¸å…³ç³»æ•°\n",
    "    rho, _ = spearmanr(X, Y)\n",
    "    \n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa8e67-f462-445b-8ed9-16ea9a290e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import clone\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "r2_mean_score= []\n",
    "rmse_mean_score= []\n",
    "mae_mean_score=[]\n",
    "# ============ æ¨¡æ‹Ÿæ•°æ® ============\n",
    "\n",
    "n_targets = Y_test.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "kf = KFold(n_splits=5, shuffle=True,random_state=1)\n",
    "second_test_predictions=[]\n",
    "\n",
    "# ============ å®šä¹‰æ¨¡å‹æ± å’Œå‚æ•°ç½‘æ ¼ ============\n",
    "model_pool = {\n",
    "    'rf': (RandomForestRegressor(), {\n",
    "        'n_estimators': [50,100,137,247,359,400],\n",
    "        'max_depth': [1,15],\n",
    "        'random_state':[7,12,18,26,74,100]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(), {\n",
    "        'n_estimators': [40,50,100,200,300,700],\n",
    "        'learning_rate': [0.05,0.1,0.5,1,2],\n",
    "        'random_state':[3,20,50,100,150,200,250]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'alpha': [0.1,0.4,0.7, 1.0]\n",
    "    }),\n",
    "    'svr': (SVR(), {\n",
    "        'C': [1.0,5.0,15, 35,87,100],\n",
    "        'kernel': ['rbf'],\n",
    "        # 'epsilon':[0.3] ,         ##############ä¼˜åŒ–å‚æ•°\n",
    "        # 'gamma':[0.1]               ###########3##ä¼˜åŒ–å‚æ•°\n",
    "    }),\n",
    "    'etr':(ExtraTreesRegressor(),{\n",
    "        'n_estimators': [50,100,157],############################\n",
    "        'max_depth': [10,17],\n",
    "        'random_state':[157]\n",
    "    }),\n",
    "    'lgb':(lgb.LGBMRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "       # 'learning_rate': [0.05,0.1,0.5,1],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'XGB':(xgb.XGBRegressor(),{\n",
    "        'n_estimators': [50,100,157,200,250,450,550],\n",
    "        'max_depth': [1,5,10,15,20],\n",
    "        'random_state':[3,10,100,157,160,200]\n",
    "    }),  \n",
    "    'LR':(LinearRegression(),{\n",
    "        \"fit_intercept\": [True]\n",
    "    }),     \n",
    "    # 'GPR':(GaussianProcessRegressor(kernel=kernel),{\n",
    "    #     'alpha': [0.1,0.4,0.7, 1.0,5.0],\n",
    "    #     'random_state':[3,10,100,157,160,200]\n",
    "    # }),  \n",
    "    # 'KNN':(KNeighborsRegressor(),{\n",
    "    #     \"n_neighbors\": [5,7,12,19,27,50,60],\n",
    "    #     \"weights\" : ['uniform', 'distance']\n",
    "    # }),  \n",
    "}\n",
    "\n",
    "# ============ Step 1: ä¸ºæ¯ä¸ªç›®æ ‡å¯»æ‰¾æœ€ä¼˜æ¨¡å‹ï¼Œå¹¶è¿›è¡ŒKæŠ˜äº¤å‰é¢„æµ‹ ============\n",
    "Y_train_level0 = {}\n",
    "Y_train_stacked = {}\n",
    "Y_test_stacked = {}\n",
    "best_base_models = []\n",
    "k_blank={}\n",
    "\n",
    "for target_idx in range(n_targets):\n",
    "    print(f\"\\nğŸ” Target {target_idx + 1}: Grid Searching Best Base Model...\")\n",
    "    model_train_preds= []\n",
    "    model_test_preds=[]\n",
    "    # è®°å½•æœ€ä¼˜æ¨¡å‹\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for name, (model, param_grid) in model_pool.items():\n",
    "        grid = GridSearchCV(clone(model), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(X_train, Y_train[:, target_idx])\n",
    "        if grid.best_score_ > best_score:\n",
    "            best_score = grid.best_score_\n",
    "            best_model = grid.best_estimator_\n",
    "            best_params = best_model.get_params()\n",
    "            #############################å•ç›®æ ‡å †å \n",
    "        stack_preds_train=np.zeros(n_samples)\n",
    "        stack_preds_test=np.zeros(n_samples)   \n",
    "        if best_score > 0.4:\n",
    "            print(f\"âœ… Model {name} selected for Target {target_idx + 1}\")\n",
    "            \n",
    "            \n",
    "            ###########################æ–°å¢çš„äº¤å‰éªŒè¯\n",
    "            for train_id, val_id in kf.split(X_train):\n",
    "                model_first = clone(best_model)\n",
    "                model_first.fit(X_train[train_id], Y_train[train_id, target_idx])\n",
    "                stack_preds_train[val_id] =model_first.predict(X_train[val_id])\n",
    "                stack_preds_test =model_first.predict(X_test)\n",
    "                  # é¢„æµ‹è®­ç»ƒé›†\n",
    "                model_test_preds.append(stack_preds_test)             ##################################################################è¿™ä¸ªåœ°æ–¹å†³å®šäº†æ˜¯æœ€åä¸€æŠ˜è¿˜æ˜¯æ‰€æœ‰æŠ˜çš„å‡å€¼\n",
    "            model_train_preds.append(stack_preds_train)\n",
    "            \n",
    "            \n",
    "            # model_train_preds.append(best_model.predict(X_train))  # é¢„æµ‹è®­ç»ƒé›†\n",
    "            # model_test_preds.append(best_model.predict(X_test))\n",
    "            valid_model_found = True\n",
    "        else:\n",
    "            valid_model_found =None\n",
    "    if valid_model_found == True:\n",
    "        # Y_train_stacked[target_idx] = np.column_stack(model_train_preds)\n",
    "        # Y_test_stacked[target_idx] = np.column_stack(model_test_preds)\n",
    "        Y_train_stacked[target_idx] = np.mean(np.column_stack(model_train_preds), axis=1)  # ç”Ÿæˆå †å ç‰¹å¾\n",
    "        Y_test_stacked[target_idx] = np.mean(np.column_stack(model_test_preds), axis=1)\n",
    "        k_blank[target_idx]=0\n",
    "    else:\n",
    "        print(f\"âš ï¸ No valid model found for Target {target_idx + 1}, skipping...\")\n",
    "        k_blank[target_idx]=1\n",
    "    best_base_models.append(clone(best_model))\n",
    "    print(f\"âœ… Best model for Target {target_idx + 1}: {best_model.__class__.__name__}, RÂ² = {best_score:.4f}\")\n",
    "    print(f\"âœ… Best model for Target {target_idx + 1}: {best_params}, RÂ² = {best_score:.4f}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    last_test_preds=[]\n",
    "    # KæŠ˜è·å–Level-0é¢„æµ‹\n",
    "    preds = np.zeros(n_samples)\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        model = clone(best_model)\n",
    "        model.fit(X_train[train_idx], Y_train[train_idx, target_idx])\n",
    "        preds[val_idx] = model.predict(X_train[val_idx])\n",
    "        preds_test= model.predict(X_test)                    ########################################äº¤å‰éªŒè¯æµ‹è¯•é›†\n",
    "        last_test_preds.append(preds_test)                   ########################################äº¤å‰éªŒè¯æµ‹è¯•é›†\n",
    "    Y_train_level0[target_idx] = preds\n",
    "    Y_test_level0[target_idx]=np.mean(np.column_stack(last_test_preds), axis=1)     ###############################################3#æµ‹è¯•\n",
    "# ============ Step 2: ä½¿ç”¨Level-0æ¨¡å‹å¯¹æµ‹è¯•é›†é¢„æµ‹ ============\n",
    "# Y_test_level0 = {}\n",
    "# for target_idx in range(n_targets):\n",
    "#     model = clone(best_base_models[target_idx])\n",
    "#     model.fit(X_train, Y_train[:, target_idx])\n",
    "#     Y_test_level0[target_idx] = model.predict(X_test)\n",
    "\n",
    "# ============ Step 3: æ¯ä¸ªç›®æ ‡æ„å»ºStackedæ¨¡å‹ ============\n",
    "final_models = []\n",
    "print(\"\\n=== Final RÂ² Scores (Stacked Single-Target with Input Expansion) ===\")\n",
    "Y_train_level0=pd.DataFrame(Y_train_level0)\n",
    "Y_test_level0=pd.DataFrame(Y_test_level0)\n",
    "for target_idx in range(n_targets):\n",
    "    first_other_idx = [i for i in range(n_targets) if i != target_idx]\n",
    "    \n",
    "    ##############################################################ç­›é€‰ç›¸å…³æ€§ç‰¹å¾\n",
    "    from scipy.stats import spearmanr\n",
    "    other_idx=[]\n",
    "    dcorr_threshold=0.3\n",
    "    for i in (first_other_idx):\n",
    "        dcorr = calculate_spearman_corr(Y_train[:,target_idx], Y_train[:,i])\n",
    "        if abs(dcorr) > dcorr_threshold:\n",
    "            other_idx.append(i)\n",
    "            \n",
    "    if k_blank[target_idx]==0:\n",
    "        X_train_ext = np.hstack((pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx]),pd.DataFrame(Y_train_stacked[target_idx])))#np.hstack([X_train, Y_train_level0[:, other_idx]])\n",
    "        X_test_ext = np.hstack((pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx]),pd.DataFrame(Y_test_stacked[target_idx])))#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "    else:\n",
    "        X_train_ext = np.hstack([pd.DataFrame(X_train), pd.DataFrame(Y_train_level0.iloc[:,other_idx])])\n",
    "        X_test_ext = np.hstack([pd.DataFrame(X_test), pd.DataFrame(Y_test_level0.iloc[:,other_idx])])#np.hstack([X_test, Y_test_level0[:, other_idx]])\n",
    "        \n",
    "        \n",
    "\n",
    "    # ä½¿ç”¨ä¸è¯¥ç›®æ ‡æœ€ä½³æ¨¡å‹ç›¸åŒç±»å‹è¿›è¡Œè®­ç»ƒ\n",
    "    model = clone(best_base_models[target_idx])\n",
    "    model.fit(X_train_ext, Y_train[:,target_idx])\n",
    "    y_pred = model.predict(X_test_ext)\n",
    "\n",
    "    r2 = r2_score(Y_test[:, target_idx], y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(Y_test[:, target_idx], y_pred))\n",
    "    mae= mean_absolute_error(Y_test[:, target_idx], y_pred)\n",
    "    print(f\"ğŸ¯ Target {target_idx+1}: {model.__class__.__name__}, Final RÂ² = {r2:.4f}\")\n",
    "    print(f\"ğŸ¯ Target {target_idx+1}: {model.__class__.__name__}, Final RMse = {rmse:.4f}\")\n",
    "    print(f\"ğŸ¯ Target {target_idx+1}: {model.__class__.__name__}, Final MAE = {mae:.4f}\")\n",
    "    final_models.append(model)\n",
    "    r2_mean_score.append(r2)\n",
    "    rmse_mean_score.append(rmse)\n",
    "    mae_mean_score.append(mae)\n",
    "    second_test_predictions.append(y_pred)\n",
    "    \n",
    "print(pd.Series(r2_mean_score).mean())\n",
    "print(pd.Series(rmse_mean_score).mean())\n",
    "print(pd.Series(mae_mean_score).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0c71e-77ca-4b26-8468-351033c21ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c81597-14b8-4d54-ae08-9249a763ad7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
